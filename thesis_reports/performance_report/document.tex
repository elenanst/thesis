\documentclass[]{article}

\usepackage[autostyle]{csquotes}

\usepackage{color}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage[
    backend=biber,
    citestyle=numeric,
    style = numeric,
    sortlocale=de_DE,
    natbib=true,
    url=false, 
    doi=true,
    eprint=false
]{biblatex}
\appto{\bibsetup}{\raggedright}
\addbibresource{bibliography.bib}
\usepackage{hyperref}
\hypersetup{
	colorlinks=true,
	citecolor = black,
	linkcolor = black,
	urlcolor = black
}
\usepackage[T1]{fontenc}
\usepackage{kpfonts}%  for math 
\usepackage{xgreek}
\usepackage{fontspec}
\setmainfont[Ligatures=TeX]{Linux Libertine O}
\usepackage{amsmath,amsfonts,amsthm, amssymb} % Math packages
\DeclareMathOperator*{\argmin}{arg\,min}
\usepackage{graphicx}	
%%% Custom headers/footers (fancyhdr package)
\usepackage{fancyhdr}
\pagestyle{fancyplain}
\fancyhead{}											% No page header
\fancyfoot[L]{}											% Empty 
\fancyfoot[C]{}											% Empty
\fancyfoot[R]{\thepage}									% Pagenumbering
\renewcommand{\headrulewidth}{0pt}			% Remove header underlines
\renewcommand{\footrulewidth}{0pt}				% Remove footer underlines
\setlength{\headheight}{13.6pt}

%%% Custom sectioning

\usepackage{sectsty}

\allsectionsfont{\centering \normalfont\scshape}

%%% Equation and float numbering
\numberwithin{equation}{section}		% Equationnumbering: section.eq#
\numberwithin{figure}{section}			% Figurenumbering: section.fig#
\numberwithin{table}{section}				% Tablenumbering: section.tab#

%%% For plotting
\usepackage{array}
\usepackage{graphicx}
\usepackage{multirow}

\newcommand\MyBox[2]{
	\fbox{\lower0.75cm
		\vbox to 1.7cm{\vfil
			\hbox to 1.7cm{\hfil\parbox{1.4cm}{#1\\#2}\hfil}
			\vfil}%
	}%
}



\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} 	% Horizontal rule

\title{
	%\vspace{-1in} 	
	\usefont{OT1}{bch}{b}{n}
	\normalfont \normalsize \textsc{} \\ 
	\horrule{0.5pt} \\[0.4cm]
	\huge Τεχνικές αξιολόγησης \\αλγορίθμων ταξινόμησης \\
	\horrule{2pt} \\[0.5cm]
}
\author{
	\normalfont 								\normalsize
	Νησιώτη Ελένη\\[-3pt]		\normalsize
	\today
}
\date{}

\setlength{\parindent}{0pt}
\setlength{\parskip}{0.5\baselineskip}%
%% ##############################
\begin{document}
	\maketitle
    \section{Σκοπός και έννοιες αξιολόγησης} 
    Στον τομέα της μηχανικής μάθησης η έννοια της αξιολόγησης σχετίζεται κυρίως με δύο προσπάθειες:
    \begin{itemize}
    	\item εξακρίβωση της δυνατότητας ενός μεμονωμένου μοντέλου να "γενικεύει", δηλαδή η απόδοση επιτευχθείσα στο σετ εκπαίδευσης να βρίσκεται κοντά στην απόδοση σε άγνωστα δεδομένα
    	\item επιλογή του βέλτιστου μοντέλου μεταξύ διαθέσιμων δεδομένης της απόδοσής τους σε συγκεκριμένο πλήθος σετ δεδομένων 
    \end{itemize}
    
    Η κοινότητα της μηχανικής μάθησης καταφεύγει σε στατιστικά εργαλεία για την εξαγωγή έγκυρων, γενικεύσιμων και ανατάξιμων συμπερασμάτων βάσει πειραμάτων. Χρησιμοποιούνται διάφορες τεχνικές, καθώς η καταλληλότητά και εφαρμοσιμότητά τους εξαρτάται από τη φύση του προβλήματος.
    \section{Τεχνικές αξιολόγησης}
    \subsection{Μετρικές αξιολόγησης}
    Η πρώτη απόφαση προς την αξιολόγηση είτε ενός είτε πολλών μοντέλων είναι το κριτήριο αξιολόγησης, δηλαδή η μετρική που αποσκοπεί να βελτιστοποιήσει το πείραμα. Η επιλογή αρχικά περιορίζεται από τους στόχους του ερευνητή και του πειράματος (χρόνος, υπολογιστική πολυπλοκότητα, ακρίβεια μοντέλου). Συχνότερος στόχος είναι η παραγωγή του ακριβέστερου μοντέλου, οπότε ο ερευνητής επιλέγει μεταξύ:
    \paragraph{Μετρικές άμεσα προερχόμενες από τον πίνακα Σύγχυσης}
    Ο πίνακας σύγχυσης για ένα μοντέλο ταξινόμησης συνοψίζει την πληροφορία σχετικά με τις προβλέψεις του και την πραγματική κλάση των παραδειγμάτων
	
	\noindent
	\renewcommand\arraystretch{1.5}
	\setlength\tabcolsep{0pt}
	\begin{center}
	\begin{tabular}{c >{\bfseries}r @{\hspace{0.7em}}c @{\hspace{0.4em}}c @{\hspace{0.7em}}l}
		\multirow{10}{*}{\rotatebox{90}{\parbox{1.5cm}{\bfseries \centering Πραγματική κλάση}}} & &  \multicolumn{2}{c}{\bfseries Προβλεπόμενη κλάση} & \\
		&  & \bfseries p & \bfseries n & \bfseries  \\
		& p$'$ & \MyBox{True}{Positive} & \MyBox{False}{Negative} &  \\[2.4em]
		& n$'$ & \MyBox{False}{Positive} & \MyBox{True}{Negative} &  \\
		&  &  &  &
	\end{tabular}
	\end{center}
	\begin{center}
		\begin{tabular}{ |l|c|c| } 
			\hline
			Ακρίβεια (\textit{accuracy}) & $\frac{TP + T N}{T P + T N + F P + F N}$  \\
			\hline 
			Ανάκληση(\textit{recall}) & $\frac{TP}{TP + FN}$  \\ 
			\hline
			Ακρίβεια (\textit{precision}) & $\frac{TP}{TP + FN}$  \\ 
			\hline
			F-μετρική(\textit{f-measure}) & $\frac{2* (precision + recall)}{precision + recall}$\\
			\hline
			Matthew συντελεστής συσχέτισης(\textit{Matthew's correlation coefficient}) & $\frac{TP * TN - FP * FN}{(TP + FP) * (TP + FN) * (TN + FP)* (TN + FN)}$\\
			\hline
		\end{tabular}
	\end{center}
    \paragraph{Area under Curve} Η μετρική αυτή προέρχεται από τη καμπύλη ROC ενός ταξινομητή και αντιστοιχεί στο εμβαδό της περιοχής κάτω από αυτήν. Με βάση την τιμή της μπορεί να διαπιστωθεί ποιοτικά η λειτουργία του ταξινομητή:
    \begin{itemize}
    	\item 0.9 - 1.0 $\rightarrow$ τέλειος ταξινομητής
    	\item 0.8 - 0.1 $\rightarrow$ καλός ταξινομητής
    	\item 0.7 - 0.8 $\rightarrow$ μέτριος ταξινομητής
    	\item 0.6 - 0.7 $\rightarrow$ κακός ταξινομητής
    	\item 0.5 - 0.6 $\rightarrow$ τυχαίος ταξινομητής
    \end{itemize} 
    \subsection{Στατιστικά tests}
    Τα πειράματα ταξινόμησης απαιτούν τη στατιστική ανάλυση πληθυσμών για την εξαγωγή συμπερασμάτων. Αν θεωρήσουμε ένα σύνολο από σετ δεδομένων δυαδικής ταξινόμησης, μερικά ερωτήματα που μπορούν να προκύψουν: υπάρχει κάποια εξάρτηση μεταξύ της κλάσης και κάποιου κατηγορικού χαρακτηριστικού για ένα συγκεκριμένο σετ δεδομένων; Ποιος αλγόριθμος είναι γενικά καλύτερος;
    
    Τα στατιστικά τεστ εφαρμόζονται σε πίνακες ενδεχομένων (\textit{contigency tables}) και έχουν ως στόχο της απόρριψη ή μη της μηδενικής υπόθεσης, η οποία αντιστοιχεί σε ανεξαρτησία των δεδομένων και τυχαιότητα των διαφορών που παρουσιάζονται μεταξύ διαφορετικών πληθυσμών. Οι πίνακες αυτοι είναι 1-way, 2-way ή 3-way, ενώ για την εμπλοκή περισσότερων πληθυσμών οι ερευνητές καταφεύγουν σε γενικευμένα γραμμικά μοντέλα. \citet{Introduction}
    
    Μερικές έννοιες που σχετίζονται με τα στατιστικά τεστ είναι:
    \begin{itemize}
    	\item υπόθεση. Προτείνεται από τον ερευνητή και χαρακτηρίζει τη στατιστική σχέση μεταξύ των δύο πληθυσμών υπό σύγκριση. Συγκρίνεται ως η εναλλακτική μιας ιδανικής μηδενικής υπόθεσης, η οποία αποκλείει οποιαδήποτε σχέση μεταξύ των δύο δειγμάτων. Στόχος του πειράματος είναι η απόρριψη της μηδενικής υπόθεσης, ενώ σε περίπτωση αποτυχίας το συμπέρασμα είναι η αδυναμία απόρριψης της μηδενικής υπόθεσης και όχι η επιβεβαίωση της εναλλακτικής.
    	\item στατιστική σημασία. Το πείραμα έχει στατιστική σημασία, όταν η σχέση μεταξύ των δειγμάτων είναι απίθανο να προκύψει από τη μηδενική υπόθεση με βάση ένα κατώφλι πιθανότητας $\alpha$.
    	\item διάστημα εμπιστοσύνης (\textit{confidence interval}). Προκύπτει από το κατώφλι πιθανότητας ως $1-\alpha$ και ερμηνεύεται ως εξής: Αν έχουμε $95 \%$ διάστημα εμπιστοσύνης τότε είμαστε κατά ίση πιθανότητα σίγουροι ότι η μέση τιμή του πληθυσμού (και όχι των δειγμάτων) θα κινείται σε συγκεκριμένα πλαίσια (που προκύπτουν από την κατανομή του test statistic).
    	\item p-value. Είναι η τιμή που οδηγεί στο αποτέλεσμα του στατιστικού πειράματος. Αποτελεί απόδειξη κατά της μηδενική υπόθεσης και όσο χαμηλότερη είναι η τιμή του τόσο ισχυρότερη η απόρριψή της. Για δεδομένο κατώφλι πιθανότητας αρκεί να είναι μικρότερο από αυτό.
    	\item σφάλματα τύπου Ι/ΙΙ. Η απόρριψη μιας έγκυρης μηδενικής υπόθεσης χαρακτηρίζεται ως σφάλμα τύπου Ι, ενώ η αδυναμία απόρριψης μιας άκυρης σφάλμα τύπου ΙΙ.
    	\item ισχύς. Πρόκειται για τη πιθανότητα το τεστ να απορρίψει μια λανθασμένη μηδενική υπόθεση.
    \end{itemize}
    \subsubsection{Pearson's chi-squared test} Πρόκειται για ένα στατιστικό τεστ μεταξύ δύο συνόλων κατηγορικών δεδομένων που εξετάζει αν οι διαφορές τους προκλήθηκαν τυχαία. Είναι κατάλληλο για unpaired δεδομένα από μεγάλα δείματα. Προέρχεται από την ευρύτερη οικογένεια των τεστς που αξιολογούνται με αναφορά στην κατανομή chi-squared, για την οποία όταν η μηδενική υπόθεση είναι αληθής η κατανομή του test statistic είναι chi-squared. 
    \paragraph{Yate's correction for continuity}
    Η τεχνική αυτή χρησιμοποιείται για διόρθωση του εξής προβλήματος: κατά την εφαρμογή του Pearson's chi-square τεστ γίνεται η υπόθεση πως η διακριτή πιθανότητα των παρατηρούμενων συχνοτήτων στον πίνακα ενδεχομένων μπορεί να προσεγγιστεί από μία συνεχή chi-squared κατανομή.
    \subsubsection{Friedman test}
    Πρόκειται για ένα μη-παραμετρικό τεστ για την ανίχνευση διαφορών μεταξύ πολλών αλγορίθμων σε πολλά σετ δεδομένων. Θεωρείται μια μη-παραμετρική εκδοχή της ANOVA, με απόρροια την απεμπλοκή από τις υποθέσεις της κανονικής κατανομής και των ίσων διακυμάνσεων των residuals και την απώλεια ισχύος.  
    
    Σημαντική προσθήκη αποτελεί η εναλλακτική test statistic που εισήγαγαν οι \cite{}, καθώς διαπίστωσαν ότι η βασική ήταν ανεπιθύμητα συντηρητική. 
    
    Σε περίπτωση διαπίστωσης σημαντικής στατιστικής διαφοράς στην απόδοση πολλών αλγορίθμων προκύπτει η ανάγκη εξακρίβωσης των ζευγαριών που οδήγησαν σε αυτό το αποτέλεσμα. Προς αυτό το σκοπό εφαρμόζονται τα εξής δύο post-hoc τεστ:
    \paragraph{Nemey} Χρησιμοποιείται κατά τη σύγκριση όλων των αλγορίθμων μεταξύ τους.
    \paragraph{Boferroni} Χρησιμοποιείται κατά τη σύγκριση όλων των αλγορίθμων με έναν αλγόριθμο -αναφορά. Αυτή η τεχνική είναι η συχνότερη, καθώς συνηθίζεται να προτείνεται ένας αλγόριθμος ως βελτίωση της τρέχουσας έρευνας.
    \subsubsection{ANOVA} Το τεστ αυτό αναλύει τη διακύμανση των δεδομένων και απορρίπτει τη μηδενική υπόθεση αν η διακύμανση μεταξύ των ταξινομητών είναι σημαντικά μεγαλύτερη από τη διακύμανση σφάλματος. Βασικές προϋποθέσεις της είναι η κανονικότητα των δειγμάτων και η σφαιρικότητα (οι τυχαίες μεταβλητές έχουν ίση διακύμανση). Απαιτούνται επίσης post-hoc τεστ για την εξακρίβωση σημαντικά διαφορετικών ζευγών αλγορίθμων.   
    \paragraph{Tukey test}
    \paragraph{Dunnett}
    \subsubsection{Fisher's exact test}
    Λέγεται ακριβές επειδή για μικρά δείγματα η σημασία της διακύμανσης από τη μηδενική υπόθεση (p-value) μπορεί να υπολογιστεί ακριβώς αντί να βασίζεται σε μια προσέγγιση που γίνεται ακριβής καθώς το μέγεθος του δείγματος πλησιάζει το άπειρο.
    \subsubsection{Wilcoxon rank test (Mann-Whitney)}
    \subsubsection{Cochran-Mantel-Haenszel}
    Χρησιμοποιείται για την εξέταση της σχέσης μεταξύ ενός δυαδικού προβλέπτη και της κλάσης λαμβάνοντας υπόψην του stratification κατά τη συλλογή των δεδομένων. Είναι γενίκευση του τεστ McNemar.
    \subsubsection{McNemar}
    \subsection{Διαγράμματα}
    \paragraph{Roc καμπύλη}
    \paragraph{Διαγράμματα performance profile}
    \citep{Dolan2002}
    \paragraph{Graphs of post-hoc tests}
    \section{Αξιολόγηση στη πράξη - Ευριστικές}
    \citep{Demsar:2006:SCC:1248547.1248548}
    \subsection{πολλά μοντέλα - 1 σετ δεδομένων}
    \begin{itemize}
    	\item το accuracy δεν είναι κατάλληλο σε μη-σταθμισμένα σετ δεδομένων
    	\item το f-measure δεν είναι κατάλληλη μετρική για το συνδυασμό recall και accuracy
    	\item το recall είναι η κατάλληλη μετρική σε προβλήματα που υπάρχει κλάση ενδιαφέροντος
    	\item μια γενικά αποδεκτή μετρική είναι το AUC
    	\item η τεχνική του 5-2 crossvalidation t-test είναι προτιμότερη από το paired t-test σε k-fold cross validation, καθώς το δεύτερο ενέχει το πρόβλημα της υποτίμησης της διακύμανσης και αυξημένου σφάλματος τύπου Ι. Το ΜcNnemar τεστ είναι εξίσου ισχυρό στις περιπτώσεις που δεν ενδείκνυται η εφαρμογή του αλγορίθμου πολλαπλές φορές.
    \end{itemize}
    \subsection{2 μοντέλα - πολλά σετ δεδομένων}
    Το πλεονέκτημα της σύγκρισης μοντέλων σε πολλά σετ δεδομένων έναντι ενός είναι πως η πηγή της διακύμανσης εντοπίζεται σε διαφορές της απόδοσης σε ανεξάρτητα σετ δεδομένων και όχι σε τυχαία δείγματα ενός σετ. Έτσι, αποφεύγεται το πρόβλημα της πολωμένης εκτίμησης της διακύμανσης και διάφορες μορφές cross-validation είναι επιτρεπτές. 
    \begin{itemize}
    	\item το t-τεστ θεωρείται ακατάλληλο για τους εξής λόγους: έχει νόημα μόνο όταν οι διαφορές στην απόδοση είναι συγκρίσιμες (ενώ στην πραγματικότητα εξαρτώνται από τη φύση του σετ δεδομένων), οι διαφορές πρέπει να έχουν κανονική κατανομή εκτός αν το δείγμα είναι αρκετά μεγάλο (γεγονός που δεν επαληθεύεται σε συνήθη πειράματα με $\approx 30$  σετ δεδομένων) και τέλος, είναι ευεπηρέαστο σε ακραίες τιμές. Προτείνεται μόνο σε περιπτώσεις που θεωρούμε ότι έχουμε αρκετά σετ δεδομένων και η απόδοση ακολουθεί κανονική κατανομή.
    	\item καταλληλότερο τεστ είναι το Wilcoxon signed rank τεστ. Απαιτεί ποιοτική και όχι ποσοτική συγκρισιμότητα (commensurability) των διαφορών, δεν προϋποθέτει κανονική κατανομή, επηρεάζεται λιγότερο από εξωκείμενες τιμές. Καθώς χρησιμοποιεί συνεχείς διαφορές η μείωση της ακρίβειας (με χρήση λιγότερων δεκαδικών) οδηγεί σε εξασθένησή του. 
    	\item η τεχική του Yate's δεν προτιμάται, καθώς καθιστά το τεστ ιδιαίτερα συντηρητικό.
    	\item το chi-squared τεστ είναι μια καλή προσέγγιση για το τεστ Fisher όταν η κατανομή του test-statistic είναι σχεδόν ίση με την κατανομή chi-squared. Στις περιπτώσεις μικρών δειγμάτων ή άνισα κατανεμημένων δεδομένων στον πίνακα ενδεχομένων αυτό δεν ισχύει. Μία ευριστική επιβεβαιώσης της μη καταλληλότητας της κατανομής chi-squared είναι οι τιμές στα κελιά του πίνακα επιβεβαιώσης να είναι κάτω από 5 ή 10 για ένα βαθμό ελευθερίας (ο κανόνας αυτός έχει αποδειχθεί υπερσυντηρητικός). \citep{Fisher}
    \end{itemize}
    \subsection{πολλά μοντέλα - πολλά σετ δεδομένων}
    Η σύγκριση πολλών μοντέλων απαιτεί εξειδικευμένα τεστ, σε αντίθεση με τη συνηθισμένη τεχνική της επέκτασης τεστ σχεδιασμένων για δύο μοντέλα, η οποία κρίνεται ακατάλληλη.
   
    Η παρουσίαση των αποτελεσμάτων σε μορφή πίνακα είναι μη επαρκής, η εξαγωγή του μέσου όρου αποτελεί υπεραπλούστευση, η μέτρηση στατιστικά σημαντικών νικών και ηττών αναξιόπιστη, το sign-test είναι αδύναμο. Η εφαρμογή paired t-test είναι ακατάλληλη για εξαγωγή συμπερασμάτων μεταξύ πολλών σετ, καθώς ένα ποσοστό των μηδενικών υποθέσεων απορρίπτεται τυχαία.  
    
    \begin{itemize}
    	\item η τεχνική ANOVA παρουσιάζει προβλήματα, καθώς προϋποθέτει κανονική κατανομή δειγμάτων και σφαιρικότητα.
    	\item προτείνεται το τεστ Friedman με post-hoc τo τεστ Holm's (αν και είναι ελάχιστα λιγότερο ισχυρό από το τεστ Hommel προσφέρει τα πλεονεκτήματα της απλότητας και ευκολότερου υπολογισμού).
    \end{itemize}
    
    \subsection{Συμπεράσματα}
    Τα παραμετρικά τεστ είναι πιο ισχυρά από τα μη-παραμετρικά όταν ισχύουν οι προϋποθέσεις τους. Καθώς στη πλειοψηφία των περιπτώσεων πειραμάτων μηχανικής μάθησης οι προϋποθέσεις δεν ικανοποιούνται (ή τουλάχιστον δεν έχουν λόγο να ικανοποιούνται) προτεινόμενα είναι τα μη-παραμετρικά.
    \printbibliography[title= Βιβλιογραφία]
\end{document}