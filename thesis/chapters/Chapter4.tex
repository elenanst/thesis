\chapter{Πειραματικά αποτελέσματα}
\section{Περιγραφή πειραμάτων}
Στόχος της παρούσας ενότητας είναι ο έλεγχος του συστήματος Automated Data Scientist, καθώς και της συνεισφοράς των τεχνικών που εφαρμόσαμε και περιγράψαμε στην Ενότητα \ref{sec:techniques}. Προς αυτό το σκοπό σχεδιάσαμε τα ακόλουθα πειράματα, τα οποία θα αναλύσουμε στη συνέχεια:
\begin{itemize}
	\item \textbf{σχεδιασμός μετρικής για ανίχνευση εξωκείμενων σετ δεδομένων}
	\item \textbf{αξιολόγηση των HPP μοντέλων}
	\item \textbf{αξιολόγηση του ensemble με προς-τα-εμπρός επιλογή μοντέλων}
	\item \textbf{συνολική αξιολόγηση του συστήματος}
\end{itemize}

\paragraph{Περιγραφή σετ δεδομένων} Για τη διεξαγωγή των πειραμάτων συλλέξαμε ένα πλήθος 123 σετ δεδομένων από διάφορες πηγές. (Στο παράρτημα \ref{appendix:Datasets} βρίσκεται ένας λεπτομερής κατάλογος περιγραφής τους.) Άξονας αναζήτησης κατά τη συλλογή ήταν η εύρεση σετ δεδομένων δυαδικής ταξινόμησης με ετερογενή χαρακτηριστικά, ώστε ο έλεγχος του συστήματος να είναι αντιπροσωπευτικός για το πραγματικό πλήθος σετ δεδομένων. Προκειμένου να υπάρχει μία κοινή διεπαφή για τα πειράματα ήταν απαραίτητος ο "καθαρισμός" των σετ δεδομένων μέσω των ακόλουθων βημάτων:
\begin{itemize}
	\item \textbf{μετατροπή αρχείων σε comma-delimited .csv} Τα πηγαία αρχεία βρίσκονταν σε μορφές .csv, .txt, .xlsx, .arff και .mysql.
	\item \textbf{καθορισμός κλάσης} Στη πλειοψηφία των περιπτώσεων η κλάση αναγνωριζόταν χειροκίνητα από την περιγραφή του σετ δεδομένων. Συλλέχθηκαν και σετ δεδομένων που ήταν πολλαπλής ταξινόμησης και παλινδρόμησης. Στην πρώτη περίπτωση έγινε αντιστοίχηση σε δύο ουσιώδεις κλάσεις, ενώ στη δεύτερη βρέθηκε η μέση τιμή της μεταβλητής κλάσης και χρησιμοποιήθηκε ως κατώφλι για το διαχωρισμό των παραδειγμάτων σε δύο κλάσεις.
	\item \textbf{αναγνώριση άγνωστων τιμών} Στα αρχεία που περιείχαν άγνωστες τιμές χρησιμοποιούνταν διάφοροι συμβολισμοί ("?", "*", "") οι οποίοι αντικαταστάθηκαν από κενά, ώστε να αναγνωρίζονται από την R ως NAs (Not Available).  
\end{itemize}
\section{Σχεδιασμός μετρικής για ανίχνευση εξωκείμενων σετ δεδομένων}
Το σύστημα Automated Data Scientist απευθύνεται σε οποιοδήποτε σετ δεδομένων δυαδικής ταξινόμησης. ένα σύνολο πολύ ετερογενές ως προς πεδίο εφαρμογής, φύση χαρακτηριστικών, μέγεθος κλπ. Καθώς το σύστημά μας περιέχει μετα-μάθηση, έχουμε συλλέξει και εκπαιδευτεί σε μια αποθήκη σετ δεδομένων, η οποία αντιπροσωπεύει το κομμάτι του "κόσμου" για το οποίο έχουμε μετα-γνώση. Όταν ο χρήστης τροφοδοτεί το σύστημά μας με ένα νέο σετ δεδομένων υπάρχει το ενδεχόμενο αυτό να βρίσκεται σε ένα ανεξερεύνητο κομμάτι του "κόσμου" με αποτέλεσμα το πείραμα να είναι υποβέλτιστο. Αποτελεί λοιπόν λειτουργική απαίτηση του συστήματος ο υπολογισμός μίας μετρικής, η οποία θα εκφράζει την έλλειψη ετοιμότητας του συστήματός μας να βελτιστοποιήσει ένα άγνωστο σετ δεδομένων.


\section{Αξιολόγηση της τεχνικής βελτιστοποίησης υπερ-παραμέτρων με μετα-μάθηση και χρήση διαστημάτων πρόβλεψης}
Όπως είδαμε στην ενότητα \ref{sec:HPP} προϊόντα αυτής της τεχνικής είναι τα \gls{HPP} μοντέλα, καθένα εκ των οποίων έχει εκπαιδευτεί στη πρόβλεψη μίας υπερ-παραμέτρου ενός αλγορίθμου μηχανικής μάθησης. Σε αυτό το σημείο θα αξιολογήσουμε τα μοντέλα αυτά ως προς το σκοπό τους, δηλαδή πόσο καλά προβλέπουν τις βελτιστοποιημένες υπερ-παραμέτρους. Επίσης, θα σχολιάσουμε τη συνεισφορά της χρήσης διαστημάτων πρόβλεψης.

Για την παραγωγή των σετ μετα-δεδομένων, τα οποία χρησιμοποιούνται για την εκπαίδευση των HPP μοντέλων, είναι απαραίτητα δύο στάδια:
\begin{itemize}
	\item Εξαγωγή των μετα-χαρακτηριστικών κάθε σετ δεδομένων. Τα  81 μετα-χαρακτηριστικά που χρησιμοποιήσαμε περιγράφονται στον Πίνακα \ref{table:meta} και υπολογίστηκαν με χρήση του πακέτου mf\-Extractor του συστήματός μας. Βασίστηκαν σε εκτεταμένη βιβλιογραφική έρευνα και προσπαθούν να συμπεριλάβουν όλα τα είδη μετα-χαρακτηριστικών που εμφανίζονται σε παρόμοιες εργασίες (\citep{Brazdil2009,Reif_meta2-features:,Feurer:2014:UMI:3015544.3015549}).~\footnote{Πριν τον υπολογισμό τους έγινε μετατροπή των κατηγορικών χαρακτηριστικών σε μεταβλητές-δείκτες, ώστε να υπάρχει ομοιόμορφη αντιμετώπιση.}   
		\begin{table}[!htb]
			\begin{center}
				\caption{Λίστα μετα-χαρακτηριστικών, τα οποία χρησιμοποιήθηκαν για την εκπαίδευση των HPP μοντέλων}
				\label{table:meta}
				\scalebox{0.7}{
				\begin{tabular}{ |l|l| } 
					\hline
					\textbf{Απλά} & \textbf{Στατιστικά Aριθμητικά}  \\
					Πλήθος χαρακτηριστικών & Άθροισμα \\
					Λογάριθμος πλήθους χαρακτηριστικών & Μέση τιμή \\
					Πλήθος παραδειγμάτων & Τυπική απόκλιση \\
					Λογάριθμος πλήθους παραδειγμάτων &Ελάχιστη τιμή \\
					Πλήθος χαρακτηριστικών με άγνωστες τιμές &Μέγιστη τιμή \\
					Ποσοστό πλήθους χαρακτηριστικών με άγνωστες τιμές& Κυρτότητα\\
					Πλήθος παραδειγμάτων με άγνωστες τιμές & Λοξότητα\\
					Ποσοστό πλήθους παραδειγμάτων με άγνωστες τιμές &  Ποσοστό \gls{PC}s για $95\%$ διακύμανση\\
					Πλήθος άγνωστων τιμών &Κυρτότητα πρώτης \gls{PC} \\
					Λογάριθμος πλήθους άγνωστων τιμών&Λοξότητα πρώτης \gls{PC} \\
					Πλήθος αριθμητικών χαρακτηριστικών &  \\
					Πλήθος κατηγορικών χαρακτηριστικών & \textbf{Στατιστικά Kατηγορικά}\\
					Πιθανότητες κλάσης & Πλήθος επιπέδων \\
					Ελάχιστη πιθανότητα κλάσης & \\
					Μέγιστη πιθανότητα κλάσης & \textbf{Μετα2-}\\
					Μέση τιμή πιθανοτήτων κλάσης& Άθροισμα\\
					Τυπική απόκλιση πιθανοτήτων κλάσης & Μέση τιμή\\
					& Τυπική απόκλιση\\
					\textbf{Θεωρίας Πληροφορίας}  & Ελάχιστη τιμή\\
					Εντροπία Κλάσης & Μέγιστη τιμή\\
				    &	 Κυρτότητα\\
				    & Λοξότητα\\				
					\hline
				\end{tabular}}   
			\end{center}
				\end{table}
				
Καθώς το πλήθος των μετα-χαρακτηριστικών είναι δυσανάλογο των διαθέσιμων σετ δεδομένων για εκπαίδευση των \gls{HPP} μοντέλων, θα επιστρατευθούν τεχνικές επιλογής των βέλτιστων. Σε πρώτη φάση αφαιρέσαμε τα γραμμικά συσχετισμένα χαρακτηριστικά, όπως αυτά υπολογίστηκαν στο σετ δεδομένων εκπαίδευσης. H τελική λίστα παρουσιάζεται στον Πίνακα \ref{table:meta2}:	

	 \begin{table}[!htb]
	 	\footnotesize
	 	\begin{center}
	 		\caption{Λίστα μετα-χαρακτηριστικών μετά από εφαρμογή φιλτραρίσματος}
	 		\label{table:meta2}
	 		\begin{tabular}{ |l|l| } 
	 			\hline
	 		     Άθροισμα αθροισμάτων & Τυπική απόκλιση επιπέδων    \\
	 			Άθροισμα μέγιστων τιμών &  Κυρτότητα επιπέδων  \\
	 			Μέση τιμή τυπικών αποκλίσεων  & Λοξότητα επιπέδων    \\
	 		    Μέση τιμή ελαχίστων τιμών &  Πλήθος χαρακτηριστικών  \\
	 			Μέση τιμή κυρτοτήτων &   Λογάριθμος πλήθους χαρακτηριστικών \\
	 			Μέση τιμή λοξοτήτων &    Πλήθος παραδειγμάτων\\
	 			Τυπική απόκλιση ελαχίστων τιμών & Λογάριθμος πλήθους παραδειγμάτων   \\
	 			Ελάχιστη τιμή μέσων τιμών &  Ποσοστό αγνώστων τιμών  \\
	 			Ελάχιστη τιμή τυπικών αποκλίσεων &  Πλήθος αριθμητικών χαρακτηριστικών  \\
	 			Ελάχιστη τιμή ελαχίστων τιμών &  Πλήθος κατηγορικών χαρακτηριστικών  \\
	 			Ελάχιστη τιμή μεγίστων τιμών &  Μέγιστη πιθανότητα κλάσης    \\
	 			Ελάχιστη τιμή λοξοτήτων & Μέση τιμή πιθανοτήτων κλάσης   \\
	 			Κυρτότητα ελαχίστων τιμών & Ποσοστό \gls{PC} για $95\%$ διακύμανση  \\
	 			Κυρτότητα μεγίστων τιμών & Κυρτότητα πρώτης \gls{PC}   \\
	 			Λοξότητα λοξοτήτων & Λοξότητα \gls{PC}   \\
	 		    Άθροισμα επιπέδων &    \\
	 			\hline
	 		\end{tabular}    
	 	\end{center}
	 \end{table}
	\FloatBarrier
	\item Εύρεση των βέλτιστων υπερ-παραμέτρων για κάθε αλγόριθμο. Προς αυτό το σκοπό χρησιμοποιήθηκε η βιβλιοθήκη HPOlib, την οποία έχουμε περιγράψει στην Eνότητα \ref{section:tools}. Ο αλγόριθμος που επιλέχθηκε ήταν ο Tree Parzen Estimator, καθώς είναι σημαντικά ταχύτερος από τους υπόλοιπους. Από τη πλευρά μας ήταν απαραίτητος ο ορισμός του χώρου αναζήτησης υπερ-παραμέτρων και της συνάρτησης κόστους για κάθε αλγόριθμο, η οποία ορίστηκε ως $ Cost = 1- Accuracy$. Στον Πίνακα \ref{table:algorithms} μπορούμε να δούμε τους αλγορίθμους μάθησης με τους οποίους ασχοληθήκαμε, καθώς και τις υπερ-παραμέτρους τους.

\end{itemize}
	\begin{table}[!htb]
		\begin{center}
				\caption[Οι αλγόριθμοι που χρησιμοποιεί το σύστημα Automated Data Scientist και οι υπερ-παράμετροί του]{Οι αλγόριθμοι που χρησιμοποιεί το σύστημα Automated Data Scientist και οι υπερ-παράμετροί τους, όπως τις ορίζει το πακέτο caret. knn: κ-κοντινότερος γείτονας, rpart: δέντρο ταξινόμησης και παλινδρόμησης (CART), nnet: \gls{ΤΝΔ}, svmRadial: \gls{SVM} με χρήση γκαουσιανού πυρήνα.}
				\label{table:algorithms}
			\begin{tabular}{ |c|c|c|c| } 
				\hline
				knn & rpart & nnet & svmRadial \\
				\hline
			    k & cp & size& C \\
			     &  & decay& sigma  \\
				\hline
			\end{tabular}    
		\end{center}
	\end{table} 
	
Στα πειράματα που ακολουθούν έχουμε χρησιμοποιήσει τη τεχνική leave one out για την αξιολόγηση των μοντέλων, 10-fold cross-validation για τη ρύθμιση και ως κριτήριο της απόδοσης των μοντέλων παλινδρόμησης τη ρίζα του μέσου τετραγωνικού σφάλματος (root mean squared error).

Όσο αφορά τις τεχνικές προ-επεξεργασίας που χρησιμοποιήθηκαν: ως μέθοδο φιλτραρίσματος για επιλογή χαρακτηριστικών ορίζουμε την επιλογή των λιγότερο συσχετισμένων χαρακτηριστικών με βάση τη γραμμική συσχέτιση. Η προς-τα-εμπρός επιλογή χαρακτηριστικών γίνεται με χρήση του πακέτου Boruta~\footnote{https://cran.r-project.org/web/packages/Boruta/Boruta.pdf} και της συνάρτησης rfe του πακέτου caret. Τέλος, ο υπολογισμός των διαστημάτων πρόβλεψης γίνεται με τη τεχνική του bootstrapping, η οποία περιγράφεται στο Παράρτημα \ref{appendix:Intervals}.
 
\subsection{Πρόβλεψη υπερ-παραμέτρου πλήθους γειτόνων για αλγόριθμο k-κοντι\-νότερου γείτονα}

\paragraph{Περιγραφή προβλήματος} Η υπερ-παράμετρος κ στον αλγόριθμο κ-κοντινότερου γείτονα ορίζει πόσα από τα κοντινότερα παραδείγματα θα ληφθούν υπόψιν κατά την πρόβλεψη. Πρόκειται για μία ακέραια και θετική τιμή, το ιστόγραμμα της οποίας, μετά από τη βελτιστοποίησή της στο σετ δεδομένων εκπαίδευσης φαίνεται στο σχήμα  \ref{fig:ktpehist} για βελτιστοποίηση με χρήση του αλγορίθμου \gls{TPE} και στο \ref{fig:kgridhist} για βελτιστοποίηση με πλεγματική αναζήτηση.

\begin{figure}[!htb]
	\begin{minipage}{0.48\textwidth}
						\scalebox{0.4}{
							\input{tikz/k_tpe.tex}}
							\captionsetup[subfigure]{width=0.8\textwidth}
							\caption{Ιστόγραμμα υπερ-παραμέτρου k για βελτιστοποίηση με \gls{TPE}.}
						\label{fig:ktpehist}
	\end{minipage}
	\begin{minipage}{0.48\textwidth}
						\scalebox{0.4}{
			\input{tikz/k_grid.tex}}
			\captionsetup[subfigure]{width=0.8\textwidth}
				\caption{Ιστόγραμμα υπερ-παραμέτρου k για βελτιστοποίηση με πλεγματική αναζήτηση.}
		    \label{fig:kgridhist}
	\end{minipage}
\end{figure}

Παρατηρούμε πως στο σχήμα \ref{fig:ktpehist} το δείγμα μας είναι συγκεντρωμένο στην τιμή 4, με αποτέλεσμα οι υπόλοιπες να είναι εξωκείμενες. Καθώς η ιδιότητα αυτή καθιστά την εκπαίδευση του \gls{HPP} μοντέλου ιδιαίτερη αναπτύχθηκε μία νέα τεχνική, αυτή της πρόβλεψης με χρήση General-inflated Generalized Poisson μοντέλου, την οποία αναλύουμε στην επόμενη ενότητα. Επίσης, στην Ενότητα \ref{section:HPPk} θα εκπαιδεύσουμε ένα μοντέλο παλινδρόμησης με χρήση των τιμών που προέκυψαν από την πλεγματική αναζήτηση, θεωρώντας το κ συνεχές. 


\subsubsection{Εκπαίδευση μοντέλου παλινδρόμησης για k του k-κοντινότερου γείτονα} \label{section:HPPk}
\begin{figure}[!htb]
	\footnotesize
	\begin{center}
		\captionof{table}{Επιλογή αλγορίθμου για την υπερ-παράμετρο k του κ-κοντινότερου γείτονα}
		\begin{tabular}{ |c|c|c|c| } 
			\hline
			& Χωρίς προ-επεξεργασία & Με επιλογή χαρακτηριστικών & \pbox{20cm}{Με επιλογή χαρακτηριστικών\\ και κανονικοποίηση} \\
			\hline
			lm & --- & $14 \cdot e+15$ &  --- \\
			\hline
			lm + log & --- & $7.946205 ^{*}$~\footnote{Η συνοδεία μιας μέτρησης με $^*$ υποδηλώνει ότι κρίθηκε χρήσιμο να αφαιρεθούν κάποια παραδείγματα από το σετ ελέγχου, καθώς την επηρέαζαν υπερβολικά. Αποτελεί ικανότητα του συστήματος η αναγνώριση τέτοιων παραδειγμάτων και η αποδοχή αδυναμίας εκπαίδευσης για αυτά. }& \\
			\hline
			svmRadial & $7.387213$ &$5.813214$& --- \\
			\hline
			svmRadial + log& $6.255705$ & $5.89$& $6.096127$\\
			\hline
			ranger + log  & $5.794678$ & 5.39141 & $\bm{5.227026}$\\
			\hline
		\end{tabular}   
	\end{center}
\end{figure}

Στη συνέχεια εκπαιδεύουμε ένα μοντέλο παλινδρόμησης με χρήση του αλγορίθμου randomForest με λογαριθμικό μετασχηματισμό και εφαρμογή φιλτραρίσματος, προς-τα-εμπρός επιλογής χαρακτηριστικών και κανονικοποίησης κατά την προ-επεξεργασία.

\begin{figure}[!htb]
		\scalebox{0.85}{
			\input{tikz/k_intervals.tex}}
		\caption[Διάγραμμα διαστημάτων πρόβλεψης για υπερ-παράμετρο k]{Διάγραμμα διαστημάτων πρόβλεψης για υπερ-παράμετρο k}
\end{figure}
\FloatBarrier
\subsection{Πρόβλεψη υπερ-παραμέτρου πολυπλοκότητας για αλγόριθμo δέντρου ταξινόμησης} 
\begin{figure}[!htb]
	\footnotesize
	\begin{center}
		\captionof{table}{Επιλογή αλγορίθμου για την υπερ-παράμετρο cp του δέντρου ταξινόμησης}
		\begin{tabular}{ |c|c|c| } 
			\hline
			 & Με κανονικοποίηση & \pbox{20cm}{ Με επιλογή χαρακτηριστικών,\\ κανονικοποίηση} \\
			 \hline
			lm & --- & $1.542080$  \\
			\hline
			lm + log & --- & $0.78553$\\
			\hline
			svmRadial & --- & $0.9514741$\\
			\hline
			svmRadial + log& $0.767217$& $0.768084$\\
			\hline
			ranger + log  &$0.755421$&$\bm{0.692675}$\\
			\hline
			rpart + log & --- &$0.8007$\\
			\hline
			blackboost + log & --- & $0.800744$ \\
			\hline
			nnet + log  & --- & $1.3621$\\
			\hline
			cubist + log & --- & $\bm{0.692675}$ \\
			\hline
			xgbTree + log & --- & $1.204$\\
			\hline
		\end{tabular}   
	\end{center}
\end{figure}

Στη συνέχεια εκπαιδεύουμε ένα μοντέλο παλινδρόμησης με χρήση του αλγορίθμου randomForest με λογαριθμικό μετασχηματισμό και εφαρμογή φιλτραρίσματος, προς-τα-εμπρός επιλογής χαρακτηριστικών και κανονικοποίησης κατά την προ-επεξεργασία.

\begin{figure}[!htb]
	\scalebox{0.85}{
\input{tikz/cp_intervals.tex}}
\caption[Διάγραμμα διαστημάτων πρόβλεψης για υπερ-παράμετρο cp]{Διάγραμμα διαστημάτων πρόβλεψης για υπερ-παράμετρο cp}
\end{figure}
\FloatBarrier
\subsection{Πρόβλεψη υπερ-παραμέτρου πλάτους πυρήνα για τον αλγόριθμο \gls{SVM}} 

\begin{figure}[!htb]
	\footnotesize
	\begin{center}
		\captionof{table}{Επιλογή αλγορίθμου για την υπερ-παράμετρο sigma του \gls{SVM}}
		\resizebox{\textwidth}{!}{ 
			\begin{tabular}{ |c|c|c|c| } 
				\hline
				& Χωρίς προ-επεξεργασία & Με αφαίρεση ακραίων τιμών & Με προς-τα-εμπρός επιλογή χαρακτηριστικών  \\
				\hline
				lm & $15 \cdot e+13$ & $6.296997 ^*$ & $7 \cdot e+9$     \\
				\hline
				lm + log & $4.2 \cdot e+10 ^*$ &  $4.239327$&$2.563388^*$ \\
				\hline
				svmRadial & $2.682720$& $2.609875$ & $2.685054$  \\
				\hline
				svmRadial + log & $2.7075885$ & $2.702844$ &   \\
				\hline
				ranger & ---  & ---  &  ---  \\
				\hline
				ranger + log  & ---  &  $\bm{2.453491}$ & $2.679798$\\
				\hline
			\end{tabular}}
		\end{center}
	\end{figure}


\begin{figure}[!htb]
	\footnotesize
	\begin{center}
		\captionof{table}{Επιλογή αλγορίθμου για την υπερ-παράμετρο sigma του \gls{SVM}}
		\resizebox{\textwidth}{!}{ 
			\begin{tabular}{ |c|c|c|c| } 
				\hline
				& Με φιλτράρισμα χαρακτηριστικών & \pbox{20cm}{Με φιλτράρισμα χαρακτηριστικών,\\ αφαίρεση ακραίων τιμών} &\pbox{20cm}{Με φιλτράρισμα χαρακτηριστικών,\\ αφαίρεση ακραίων τιμών,\\ κανονικοποίηση}   \\
				\hline
				lm &  $10 \cdot e+10 $ &  $69993$& $3.076596^*$     \\
				\hline
				lm + log &Inf & $4.055437 ^*$&  $3.423858^*$\\
				\hline
				svmRadial & $2.588112$ & ---  &  $2.585245$  \\
				\hline
				svmRadial + log & $2.720634$ & $2.664860$ & $2.690744$    \\
				\hline
				ranger &  --- & $2.576414$& $2.671640$ \\
				\hline
				ranger + log  & $2.6248730$& $2.696213$ & $\bm{2.530286}$\\
				\hline
			\end{tabular}  }
		\end{center}
	\end{figure}

Στη συνέχεια εκπαιδεύουμε ένα μοντέλο παλινδρόμησης με χρήση του αλγορίθμου randomForest με λογαριθμικό μετασχηματισμό και εφαρμογή αφαίρεσης ακραίων τιμών, φιλτραρίσματος, προς-τα-εμπρός επιλογής χαρακτηριστικών κανονικοποίησης κατά την προ-επεξεργασία.
\begin{figure}[!htb]
\scalebox{0.85}{
\input{tikz/sigma_intervals.tex}}
\caption[Διάγραμμα διαστημάτων πρόβλεψης για υπερ-παράμετρο sigma]{Διάγραμμα διαστημάτων πρόβλεψης για υπερ-παράμετρο sigma}
\end{figure}
\FloatBarrier
\subsection{Πρόβλεψη υπερ-παραμέτρου κόστους για τον αλγόριθμo \gls{SVM} }
\begin{figure}[!htb]
	\footnotesize
	\begin{center}
		\captionof{table}{Επιλογή αλγορίθμου για την υπερ-παράμετρο C του \gls{SVM}}
		\begin{tabular}{ |c|c|c|c| } 
			\hline
			& Με κανονικοποίηση & Με επιλογή χαρακτηριστικών & \pbox{20cm}{Με επιλογή χαρακτηριστικών,\\κανονικοποίηση} \\
			\hline
			lm & $12.91$  & $12.8225$ & $12.82250$  \\
			\hline
			lm + log & $15.618852^*$ & $9.991954 ^{*}$& $9.991954^*$ \\
			\hline
			svmRadial & $10.401787$ &$10.507888$& $10.21597$\\
			\hline
			svmRadial + log& $11.136914$ & $10.676247$& $10.840548$\\
			\hline
			ranger + log  & $9.997852$ & $9.319905$ & $\bm{9.294558}$\\
			\hline
		\end{tabular}   
	\end{center}
\end{figure}

Στη συνέχεια εκπαιδεύουμε ένα μοντέλο παλινδρόμησης με χρήση του αλγορίθμου randomForest με λογαριθμικό μετασχηματισμό και εφαρμογή φιλτραρίσματος, προς-τα-εμπρός επιλογής χαρακτηριστικών και κανονικοποίησης κατά την προ-επεξεργασία.

\begin{figure} [!htb]
	\scalebox{0.85}{
\input{tikz/C_intervals.tex}}
\caption[Διάγραμμα διαστημάτων πρόβλεψης για υπερ-παράμετρο C]{Διάγραμμα διαστημάτων πρόβλεψης για υπερ-παράμετρο C}
\end{figure}
\FloatBarrier
\subsection{Πρόβλεψη υπερ-παραμέτρου μεγέθους για τον αλγόριθμo \gls{ANN}}
\begin{figure}[!htb]
	\footnotesize
	\begin{center}
		\captionof{table}{Επιλογή αλγορίθμου για την υπερ-παράμετρο size του \gls{ANN}}
		\resizebox{\textwidth}{!}{ 
			\begin{tabular}{ |c|c|c|c| } 
				\hline
				& \pbox{20cm}{Χωρίς\\ προ-επεξεργασία} & \pbox{20cm}{Με αφαίρεση\\ ακραίων τιμών,\\κανονικοποίηση} & \pbox{20cm}{Με φιλτράρισμα,\\προς τα εμπρός επιλογή χαρακτηριστικών (Boruta),\\αφαίρεση ακραίων τιμών} \\
			\hline
			lm + log & $4.8964 ^*$ & $4.042651$ & $2.534214$   \\
			\hline
			svmRadial & $2.354932$& $2.358656$ & $2.164228$   \\
			\hline
			svmRadial + log & $2.344243$ & $2.320754$ & $2.113830$  \\
			\hline
			ranger & ---  & ---  & $2.131324$ \\
			\hline
			ranger + log  & $2.286583$ & $2.339490$  & $2.367264$  \\
			\hline
			glm  &  ---  &  ---   &   $2.367264$  \\
			\hline
			glm + log  &  ---  &  ---   &   $2.534214$  \\
			\hline    				
			\end{tabular}  }
		\end{center}
	\end{figure}
	
\begin{figure}[!htb]
	\footnotesize
	\begin{center}
		\captionof{table}{Επιλογή αλγορίθμου για την υπερ-παράμετρο size του \gls{ANN}}
		\resizebox{\textwidth}{!}{ 
			\begin{tabular}{ |c|c|c| } 
				\hline
				 & \pbox{20cm}{Με φιλτράρισμα,\\προς τα εμπρός επιλογή χαρακτηριστικών (Boruta),\\αφαίρεση ακραίων τιμών,\\ κανονικοποίηση} & \pbox{20cm}{Με φιλτράρισμα,\\προς τα εμπρός επιλογή χαρακτηριστικών (rfe),\\κανονικοποίηση, αφαίρεση ακραίων τιμών} \\
				\hline
				lm + log  & $2.534214$&  ---  \\
				\hline
				svmRadial  & $2.113806$ & 2.208724  \\
				\hline
				svmRadial + log & $\bm{2.045345}$ &  2.180961  \\
				\hline
				ranger & $2.115296$ &  ---  \\
				\hline
				ranger + log  & $2.135809$ & \\
				\hline
				glm   & $2.367264$ & --- \\
				\hline
				glm + log  & $2.53421417$ &  --- \\
				\hline    				
			\end{tabular}  }
		\end{center}
	\end{figure}
	
Στη συνέχεια εκπαιδεύουμε ένα μοντέλο παλινδρόμησης με χρήση του αλγορίθμου svmRadial με λογαριθμικό μετασχηματισμό και εφαρμογή αφαίρεσης ακραίων τιμών, φιλτραρίσματος, προς-τα-εμπρός επιλογής χαρακτηριστικών και κανονικοποίησης κατά την προ-επεξεργασία.
\begin{figure}[!htb]
	\scalebox{0.85}{
	\input{tikz/size_intervals.tex}}
    \caption[Διάγραμμα διαστημάτων πρόβλεψης για υπερ-παράμετρο size]{Διάγραμμα διαστημάτων πρόβλεψης για υπερ-παράμετρο size}
\end{figure}
\FloatBarrier
\subsection{Πρόβλεψη υπερ-παραμέτρου φθοράς για τον αλγόριθμo \gls{ΤΝΔ}} 
\begin{figure}[!htb]
	\footnotesize
	\begin{center}
		\captionof{table}{Επιλογή αλγορίθμου για την υπερ-παράμετρο decay του \gls{ΤΝΔ}}
		\resizebox{\textwidth}{!}{ 
			\begin{tabular}{ |c|c|c|c| } 
				\hline
				& \pbox{20cm}{Με αφαίρεση\\ ακραίων τιμών} & \pbox{20cm}{Με αφαίρεση\\ ακραίων τιμών\\κανονικοποίηση} & \pbox{20cm}{Με φιλτράρισμα, \\προς τα εμπρός επιλογή χαρακτηριστικών (Boruta)\\ και αφαίρεση ακραίων τιμών} \\
				\hline
				lm  & $1.3346 ^*$ & 1.340122  & 0.2674278  \\
				\hline
				lm + log & $2.08406 ^*$ & 2.084079 & 0.277538  \\
				\hline
				svmRadial & 0.279624 & 0.279403  & 0.270774   \\
				\hline
				svmRadial + log & 0.252120  & 0.253401 & 0.251316  \\
				\hline
				ranger & 0.276386 & 0.285601 & 0.244 \\
				\hline
				ranger + log  & 0.250204 &  0.248379 & 0.24289  \\
				\hline    				
			\end{tabular}}
		\end{center}
	\end{figure}
	
\begin{figure}[!htb]
	\footnotesize
	\begin{center}
		\captionof{table}{Επιλογή αλγορίθμου για την υπερ-παράμετρο decay του \gls{ΤΝΔ}}
		\resizebox{\textwidth}{!}{ 
			\begin{tabular}{ |c|c|c| } 
				\hline
				& \pbox{20cm}{Με φιλτράρισμα, \\προς τα εμπρός επιλογή χαρακτηριστικών (Boruta)\\, αφαίρεση ακραίων τιμών\\ και κανονικοποίηση} & \pbox{20cm}{Με φιλτράρισμα, \\προς τα εμπρός επιλογή χαρακτηριστικών (rfe),\\ κανονικοποίηση και αφαίρεση ακραίων τιμών} \\
				\hline
				lm    & 0.267428 &   --- \\
				\hline
				lm + log & 0.277538&  ---  \\
				\hline
				svmRadial & 0.268606  & 0.267425   \\
				\hline
				svmRadial + log  & 0.252016  & 0.255515   \\
				\hline
				ranger  & 0.247057  &  ---  \\
				\hline
				ranger + log    & $\bm{0.240159}$  & --- \\
				\hline    				
			\end{tabular}}
		\end{center}
	\end{figure}
	
Στη συνέχεια εκπαιδεύουμε ένα μοντέλο παλινδρόμησης με χρήση του αλγορίθμου randomforest με λογαριθμικό μετασχηματισμό και εφαρμογή αφαίρεσης ακραίων τιμών, φιλτραρίσματος, προς-τα-εμπρός επιλογής χαρακτηριστικών και κανονικοποίησης κατά την προ-επεξεργασία.

\begin{figure}[!htb]
	\scalebox{0.85}{
	\input{tikz/decay_intervals.tex}}
	\caption[Διάγραμμα διαστημάτων πρόβλεψης για υπερ-παράμετρο decay]{Διάγραμμα διαστημάτων πρόβλεψης για υπερ-παράμετρο decay}
\end{figure}
\FloatBarrier

\paragraph{Συμπεράσματα}
Τα μοντέλα HPP που εκπαιδεύσαμε δεν καταφέρνουν να προβλέψουν επακριβώς τις υπερ-παραμέτρους. Το γεγονός αυτό μάλλον οφείλεται στα μετα-χαρακτη\-ρι\-στικά και συγκεκριμένα την αδυναμία τους να περιγράψουν τις συναρτήσεις-στόχους που θέσαμε. Τα πειράματά μας ωστόσο αποκαλύπτουν την ύπαρξη κάποια συσχέτισης μεταξύ αυτών και των μετα-χαρακτηριστικών.

Η προσθήκη των διαστημάτων πρόβλεψης αποδεικνύεται ότι αναιρεί την αδυναμία των μοντέλων HPP, καθώς η βέλτιστη τιμή βρίσκεται συνήθως μέσα στο διάστημα πρόβλεψης. Συγκεκριμένα το ποσοστό των σετ δεδομένων ελέγχου για το οποίο η σωστή τιμή της υπερ-παραμέτρου βρίσκεται μέσα στο διάστημα πρόβλεψης είναι 0.7826 για το k, 0.8695 για το cp, 0.8695 για το sigma, 0.9565 για το C, 1 για το size και 0.6086 για το decay. Βέβαια, ακόμη και στις περιπτώσεις που δε βρίσκεται μέσα, παρατηρούμε πως δεν απέχει πολύ. Η επίτευξη αυτή προσδίδει βαρύτητα στην αξιολόγηση του ensemble, η οποία ακολουθεί.  

\section{Αξιολόγηση της τεχνικής σχηματισμού ensemble με προς τα εμπρός επιλογή μοντέλων} \label{section:tensemble}
H αξιολόγηση της τεχνικής ensemble που χρησιμοποιήσαμε επιχειρεί να επιβεβαιώσει την προσδοκία ότι ο ensemble παρουσιάζει τουλάχιστον το ίδιο καλή απόδοση με το καλύτερο μοντέλο, το οποίο βρίσκεται στην αποθήκη βελτιστοποιημένων μοντέλων. 

Για τα πειράματά μας εκπαιδεύουμε τα μοντέλα στο $80\%$ των σετ δεδομένων και κρατάμε τα υπόλοιπα για την αξιολόγηση του ensemble, η οποία γίνεται ως εξής: εξάγονται τα μετα-χαρακτηριστικά των σετ δεδομένων, προβλέπονται οι βέλτιστες υπερ-παράμετροι για κάθε αλγόριθμο μάθησης, εκπαιδεύονται τα μοντέλα και τέλος σχηματίζεται ο ensemble. Για κάθε σετ δεδομένων καταγράφεται η απόδοση του ensemble και του βέλτιστου μοντέλου ως η ακρίβεια (accuracy) που επιτεύχθηκε με 10-fold cross-validation. 

Για την αξιολόγηση του συστήματος θα χρησιμοποιηθούν δύο τεχνικές της σύγχρονης βιβλιογραφίας: στατισικά τεστ για τη διαπίστωση σημαντικής διαφοράς στην απόδοση των αλγορίθμων και διαγράμματα προφίλ απόδοσης για την οπτικοποίηση της απόδοσης των αλγορίθμων στα διαφορετικά σετ δεδομένων, τα οποία θα αναλύσουμε στη συνέχεια.

\paragraph{Διαγράμματα προφίλ απόδοσης} 	Τα διαγράμματα προφίλ απόδοσης (performance profile plots) \citep{Dolan2002} αποτελούν ένα εργαλείο αξιολόγησης και σύγκρισης της απόδοσης εργαλείων βελτιστοποίησης. Χρησιμοποιούνται σε περιπτώσεις εφαρμογής διαφορετικών τεχνικών βελτιστοποίησης σε ένα σύνολο προβλημάτων ως εναλλακτική απεικόνιση εκτενών πινάκων, μιας συνηθισμένης και προβληματικής λύσης. Το προφίλ απόδοσης είναι η αθροιστική συνάρτηση κατανομής μιας τεχνικής για μία μετρική απόδοσης.

Ως μετρική απόδοσης ορίζουμε το λόγο της απόδοσης της τρέχουσας τεχνικής προς τη μεγαλύτερη απόδοση που επιτεύχθηκε από οποιαδήποτε τεχνική για ένα συγκεκριμένο σετ δεδομένων, δηλαδή

\begin{equation}
r_{p,s}= \frac{t_{p,s}}{\max\{{t_{p,s} : s \in S}\}}    
\end{equation} 

όπου r ο λόγος απόδοσης, t η απόδοση, p το σετ δεδομένων και s η τεχνική.

Το διάγραμμα απεικονίζει τη τιμή
\begin{equation}
\rho_{\tau}= \frac{size\{{p \in P : r_{p,s} \leq \tau  }\}}{n_p}   
\end{equation}

όπου $n_p$ το πλήθος των σετ δεδομένων. Η τιμή αυτή εκφράζει την πιθανότητα μία τεχνική να βρίσκεται σε απόσταση $\tau$ από τον καλύτερο λόγο απόδοσης.  Επομένως το σημείο $\tau = 1$ εκφράζει τη πιθανότητα μία τεχνική να είναι η βέλτιστη.

\begin{figure}[!htb]
	\scalebox{0.75}{
	\input{tikz/performance_ensemble.tex}}
		\caption[Διάγραμμα προφίλ απόδοσης για τη σύγκριση του ensemble με το βέλτιστο μοντέλο]{Διάγραμμα προφίλ απόδοσης για τη σύγκριση του ensemble με το βέλτιστο μοντέλο: Παρατηρούμε πως o ensemble υπερισχύει του βέλτιστου μοντέλου σε όλα τα σετ δεδομένων. }
		\label{fig:ensprof}
\end{figure}

Η εφαρμογή του Wilcoxon rank-sum τεστ με επίπεδο εμπιστοσύνης $95\%$, εφαρμογή διόρθωσης συνέχειας (Παράρτημα \ref{appendix:Tests}) και συνυπολογισμό του ότι τα πειράματα είναι ζευγαρωμένα (paired) δίνει p-value 0.8336.  

\paragraph{Συμπεράσματα}
Το διάγραμμα απόδοσης του Σχήματος \ref{fig:ensprof} και το στατιστικό τεστ που εφαρμόσαμε συμφωνούν ότι ο ensemble έχει απόδοση ισότιμη του καλύτερου μοντέλου της βιβλιοθήκης και δεν υπάρχει στατιστικά σημαντική διαφορά μεταξύ τους. Το διάγραμμα απόδοσης επίσης δίνει μεγαλύτερη πιθανότητα στον ensemble να έχει απόδοση πλησιέστερη στη βέλτιστη.
 
\section{Αξιολόγηση συστήματος Automated Data Scientist}\label{section:eval_system}
Η αξιολόγηση του Automated Data Scientist στοχεύει να αποδείξει ότι το σύστημα που έχουμε σχεδιάσει έχει απόδοση συγκρίσιμη με τεχνικές της σύγχρονης βιβλιογραφίας. Καθώς η ουσιαστική πρωτοτυπία του συστήματος βρίσκεται στον τρόπο με τον οποίο γίνεται η βελτιστοποίηση των υπερ-παρα\-μέ\-τρων για τα μοντέλα μηχανικής μάθησης που χρησιμοποιούμε θα συγκρίνουμε το σύστημά μας με δύο τεχνικές βελτιστοποίησης:
\begin{itemize}
	\item \textbf{πλεγματική αναζήτηση} Πρόκειται για τη συνηθέστερη τεχνική αναζήτησης υπερπαρα\-μέτρων μέχρι και σήμερα.
	\item \textbf{Tree Parzen Estimator} Η τεχνική αυτή, που έχει περιγραφεί στην ενότητα \ref{section:SMBO} αποτελεί state of the art στο χώρο του AutoML.
\end{itemize}

Eπίσης, προκειμένου να αξιολογηθεί η συνεισφορά της τεχνικής σχηματισμού ensemble  με προς-τα-εμπρός επιλογής μοντέλων πραγματοποιούμε 4 διαφορετικά πειράματα: ένα για κάθε αλγόριθμο μάθησης, όπου εκπαιδεύονται μοντέλα μόνο με το συγκεκριμένο και ένα συνολικό, όπου ο ensemble χρησιμοποιεί όλους τους αλγορίθμους. 

Για την αξιολόγηση του συστήματος θα χρησιμοποιηθούν δύο τεχνικές της σύγχρονης βιβλιογραφίας: στατισικά τεστ για τη διαπίστωση σημαντικής διαφοράς στην απόδοση των αλγορίθμων και διαγράμματα προφίλ απόδοσης για την οπτικοποίηση της απόδοσης των αλγορίθμων στα διαφορετικά σετ δεδομένων. 

Εφαρμόζωντας το στατιστικό τεστ Friedman rank sum για σύγκριση μεταξύ πολλαπλών αλγορίθμων διαπιστώνουμε σημαντική στατιστική διαφορά καθώς το p-value είναι $6.285 \cdot 10^{-5}$ για επίπεδο εμπιστοσύνης $0.95$. Προκειμένου να εντοπίσουμε τα ζεύγη των αλγορίθμων τα οποία προκαλούν τη σημαντική στατιστική διαφορά θα εφαρμόσουμε το Nemenyi post-hoc τεστ.

	\begin{table}[!htb]
		\begin{center}
			\caption[Στατιστικό τεστ απόδοσης συνολικού συστήματος]{Ο πίνακας αυτός περιέχει τα p-values του post-hoc Nemenyi τεστ για τη διαπίστωση στατιστικής διαφοράς μεταξύ των διαφορετικών μεθόδων ανά ζεύγη. Το τεστ αυτό εφαρμόστηκε μετά από τη διαπίστωση στατιστικής διαφοράς με το Friedman rank sum τεστ. Με έντονη γραφή παρουσιάζονται τα ζεύγη τα οποία εμφανίζουν στατιστικά σημαντική διαφορά.}
			\label{table:pvalues}
			\scalebox{0.8}{
			\begin{tabular}{ |c|c|c|c|c|c|c|c|c| } 
				\hline
				&automl & ensembleGrid & ensembleTpe & knnGrid & nknnTpe & nnetGrid & nnetTpe & treeGrid\\
				\hline
			    ensembleGrid & $\bm{0.0021}$ &  ---  &  ---  &  ---  & ---  & ---  & ---  & ---  \\
			    ensembleTpe & $\bm{0.0021}$ & 1 & ---  & ---  & ---  & ---  & ---  & --- \\
			    knnGrid & 0.9213 & 0.1593 & 0.1593 &  --- &  --- & ---  & ---  & ---  \\
			    knnTpe & 0.9213 & 0.1593 & 0.1593& 1 &  --- & ---  & ---  &  --- \\
			    nnetGrid & 0.2337 & 0.8531 & 0.8531 & 0.9643& 0.9643 &- & --- & --- \\
			    nnetTpe & 0.7854 & 0.3024 & 0.3024 & 1 & 1 & 0.9949 & ---  & --- \\
			    treeGrid & 0.8321 & 0.2554 & 0.2554 & 1 & 1 & 0.9902 & 1 & --- \\
			    treeTpe & 1 & $\bm{0.0067}$ & $\bm{0.0067}$ & 0.9828 & 0.9828 & 0.409 & 0.9213 & 0.9457 \\	    
				\hline
			\end{tabular}}
		\end{center}			
	\end{table} 


\begin{figure}[!htb]
	\scalebox{0.8}{
	\input{tikz/performance_grid.tex}}
	\caption{Διάγραμμα προφίλ απόδοσης συνολικού συστήματος}
	\label{fig:systemprofgrid}
\end{figure}


\begin{figure}[!htb]
	\scalebox{0.8}{
	\input{tikz/performance_tpe.tex}}
	\caption{Διάγραμμα προφίλ απόδοσης συνολικού συστήματος}
	\label{fig:systemproftpe}
\end{figure}
	
\paragraph{Συμπεράσματα}
Με τη βοήθεια του Πίνακα \ref{table:pvalues} μπορούμε να αναγνωρίσουμε τα ζεύγη αλγορίθμων που παρουσιάζουν σημαντική διαφορετική απόδοση στα σετ δεδομένων ελέγχου. Το σύστημά μας διαφέρει σημαντικά μόνο με τις μεθόδους ensembleGrid και ensembleTpe.
Επίσης, σύμφωνα με τα Σχήματα \ref{fig:systemprofgrid} και \ref{fig:systemproftpe} η μέθοδος με την καλύτερη απόδοση σε όλα τα σετ δεδομένων είναι η , ενώ το σύστημά μας . 

Το σύστημά μας είναι εξίσου αποδοτικό με τις τρέχουσες τεχνικές σχεδόν σε όλα τα σετ εκπαίδευσης ελέγχου. Επίσης, έχει επιτευχθεί η αντικατάσταση της χρονοβόρας βελτιστοποίησης υπερ-παραμέτρων με απλή πρόβλεψη και η δημιουργία μετα-γνώσης, χαρακτηριστικά που δε συνδέονται άμεσα με την απόδοση του συστήματος, ωστόσο επιφέρουν υπολογιστικά οφέλη και δυνατότητες εκμετάλλευσης. Συμπεραίνουμε επομένως πως το σύστημά μας αποτελεί χρήσιμη προσθήκη στο σύνολο των \gls{AutoML} εργαλείων. 