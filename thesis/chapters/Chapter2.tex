\chapter{Θεωρητικό Υπόβαθρο}	
\section{Μηχανική Μάθηση}
Στην ενότητα αυτή θα τοποθετήσουμε εννοιολογικά τον όρο μηχανική μάθηση, θα ορίσουμε μία καθολική ορολογία και θα περιγράψουμε συνοπτικά τη ροή ενός πειράματος μηχανικής μάθησης.

\subsection{Η έννοια της μηχανικής μάθησης}
Η μηχανική μάθηση αναδύθηκε από τον επιστημονικό τομέα της Τεχνητής Νοημοσύνης, η οποία μελετά την ικανότητα υπολογιστικών συστημάτων να επιδείξουν ευφυΐα. Στο άρθρο \textit{Υπολογιστική Μηχανική και Νοημοσύνη} \citep{Turing:1995:CMI:216408.216410} ο Allan Turing επιχειρεί να αντιμετωπίσει την εγγενή ασάφεια των όρων "μηχανή" και "σκέφτομαι" μέσω ενός συλλογισμού, που αποκαλεί \textit{Το Παιχνίδι της Μίμησης}. To "παιχνίδι" έγκειται στην προσπάθεια ανίχνευσης Τεχνητής Νοημοσύνης ως απάντηση στο ερώτημα: "Μπορεί μία μηχανή να πείσει για την ανθρώπινη ιδιότητά της"; Με παρόμοια συλλογιστική ο Tom M. Mitchel \citep{Mitchell:1997:ML:541177} κατέληξε στον ακόλουθο φορμαλιστικό ορισμό της μηχανικής μάθησης: 

\begin{displayquote}
	\textit{
	Λέμε πως ένα πρόγραμμα υπολογιστή μαθαίνει από μια εμπειρία \textit{Ε}, αναφερόμενοι σε ένα σύνολο καθηκόντων \textit{Τ} και ένα μέτρο απόδοσης \textit{P}, αν η απόδοση του στα καθήκοντα \textit{T}, όπως μετράται από το \textit{P}, βελτιώνεται καθώς αποκτά εμπειρία \textit{Ε}. }
\end{displayquote}

Πρακτικά το πρόγραμμα αντιλαμβάνεται την εμπειρία ως δεδομένα, τα οποία περιγράφουν ένα πρόβλημα και καλείται να εξάγει συμπεράσματα ώστε να προβλέψει μελλοντικές συμπεριφορές. Ανάλογα με τη μορφή του καθήκοντος η μηχανική μάθηση διακρίνεται σε:

\begin{itemize}
	\item \textbf{Επιβλεπόμενη μάθηση (Supervised learning)} Το πρόγραμμα λαμβάνει πληροφορία τόσο για τα χαρακτηριστικά του προβλήματος όσο και για τη συμπεριφορά που καλείται να προβλέψει. Για παράδειγμα, αν θέλουμε να προβλέψουμε την τιμή των ακινήτων μιας περιοχής θα συλλέξουμε χαρακτηριστικά όπως η τοποθεσία, τα τετραγωνικά μέτρα και η τιμή κάποιων κατοικιών και θα χρησιμοποιήσουμε το πρόγραμμα για τη πρόβλεψη των τιμών άλλων κατοικιών με βάση την τοποθεσία και το μέγεθός τους.
	\item \textbf{Μη επιβλεπόμενη μάθηση (Unsupervised learning)} Σε αυτήν την περίπτωση το πρόγραμμα αναλαμβάνει να ανακαλύψει δομικά πρότυπα στα δεδομένα χωρίς να διαθέτει πληροφορία για τη προβλεπόμενη συμπεριφορά. Αν λοιπόν η Amazon στοχεύει να αναγνωρίσει τους τύπους των πελατών της, ώστε να μεγιστοποιήσει το κέρδος της προβάλλοντας σε κάθε τύπο προσαρμοζόμενες διαφημίσεις, θα χρειαστεί ένα πρόγραμμα, το οποίο θα τους ομαδοποιεί σε ομοιογενείς ομάδες με βάση χαρακτηριστικά όπως οι αγορές, η καταγωγή κτλ.
	\item \textbf{Ενισχυτική Μάθηση (Reinforcement learning)} Ούτε σε αυτή τη μορφή το πρόγραμμα διαθέτει πληροφορία για τη προβλεπόμενη συμπεριφορά, η προσέγγιση ωστόσο είναι διαφορετική: το πρόγραμμα δρα σε ένα δυναμικό περιβάλλον, με το οποίο αλληλεπιδρά μέσω ανταμοιβών στις προβλέψεις του. Όπως ακριβώς ένα παιδί χρειάζεται να ακουμπήσει μερικές φορές κάτι καυτό για να μάθει ότι δεν πρέπει να το ξανακάνει, έτσι και ένας πράκτορας λογισμικού χρειάζεται να δοκιμάσει διάφορες κινήσεις στο σκάκι για να μάθει να κερδίζει.
\end{itemize}

Ένας ακόμη διαχωρισμός των προβλημάτων μηχανικής μάθησης προκύπτει από το είδος της προβλεπόμενης συμπεριφοράς:

\begin{itemize}
	\item \textbf{Προβλήματα παλινδρόμησης (Regression)} Πρόκειται για προβλήματα πρόβλεψης μιας συνεχούς τιμής, όπως η τιμή πώλησης ακινήτων.
	\item \textbf{Προβλήματα ταξινόμησης (Classification)} Εδώ ενδιαφερόμαστε να αναγνωρίσουμε την κατηγορία, στην οποία ανήκει ένα δεδομένο. Για παράδειγμα ένα εργοστάσιο ενδιαφέρεται για τη πρόβλεψη ελαττωματικών εξαρτημάτων με βάση τα χαρακτηριστικά τους.
	\item \textbf{Προβλήματα ομαδοποίησης (Clustering)} Σε αυτή τη περίπτωση γίνεται αναγνώριση ομάδων με βάση την ομοιογένειά τους, όπως στο παράδειγμα που χρησιμοποιήσαμε για τη περιγραφή της Μη Επιβλεπόμενης Μάθησης.
\end{itemize}

Στη συνέχεια θα εστιάσουμε στην επιβλεπόμενη μάθηση σε προβλήματα ταξινόμησης, καθώς αποτελούν το πεδίο εφαρμογής της παρούσας διπλωματικής εργασίας.
 
\subsubsection{Ορολογία} \label{section:terminology}
 Με κίνητρο τη χρήση ενός κοινού λεξιλογίου θα ορίσουμε βασικές έννοιες που χρησιμοποιούνται συχνά στη βιβλιογραφία μέσω ενός παραδείγματος. Έστω το πρόβλημα πρόβλεψης της κακοήθειας ενός όγκου με βάση την ηλικία και το μέγεθός του. Τότε ορίζουμε ως:
 
\begin{figure}[!htb]
	\centering
	\begin{tikzpicture}
	\begin{axis}[xlabel= Ηλικία,ylabel=Μέγεθος, xmin=-6, xmax = 6, ymax = 7.5, ymin = -1.5,legend style = {font=\small},yticklabels={,,},xticklabels={,,},legend cell align=left,]
	\addplot[
	visualization depends on={\thisrow{nodes}\as\myvalue},
	scatter/classes={
		a={mark=*,black},
		b={mark=*,gray}
	},
	scatter, only marks,
	scatter src=explicit symbolic,
	]
	table[x=x,y=y,meta=label]
	{data/scattered_example.dat};
	
	\addplot [draw=black,fill=black, opacity = 0.2]
	coordinates { (-6,7.5) (-6,-1.5) (6,-1.5)};
	\addplot [draw=black,fill=black, opacity = 0.5]
	coordinates {(6,-1.5) (6,7.5) (-6,7.5)};
	\addlegendentry{Κακοήθης}
	\addlegendentry{Μη κακοήθης}
	\addplot[color=black,domain=-6:6,]{-3/4*x +3};
	\end{axis}
	\end{tikzpicture}
	\caption[Ορολογία μηχανική μάθησης]{Ορολογία μηχανική μάθησης: Οι άξονες του διαγράμματος αντιστοιχούν στα χαρακτηριστικά του προβλήματος και τα σημεία στα παραδείγματα, για τα οποία η κλάση απεικονίζεται με το χρώμα. Η υπόθεση h αντιστοιχεί στη γραμμή, η οποία διαχωρίζει το πρόβλημα σε δύο υποχώρους.}	
	\label{fig:terminology}
\end{figure}

\begin{itemize}
	\item \textbf{Χαρακτηριστικά $x_n$} Τα στοιχεία που περιγράφουν το πρόβλημα, δηλαδή το μέγεθος και η ηλικία του όγκου.
	\item \textbf{Κλάση $y_n$} Πρόκειται για το στοιχείο που θέλουμε να προβλέψουμε, στην προκειμένη, τη κακοήθεια του όγκου.
	\item \textbf{Παραδείγματα $(x_n, y_n)$} Τα δεδομένα του προβλήματος δίνονται συνήθως σε μορφή πίνακα: κάθε γραμμή αποτελεί ένα παράδειγμα και οι στήλες περιέχουν τα χαρακτηριστικά και την κλάση.
	\item \textbf{Συνάρτηση-στόχος $f: X \rightarrow Y$} Είναι η άγνωστη συνάρτηση, που ορίζει πως προκύπτει η κλάση από τα χαρακτηριστικά του προβλήματος. Σκοπός της μηχανικής μάθησης είναι η προσέγγισή της, η οποία θα γίνει με τη βοήθεια των πεπερασμένων παραδειγμάτων που διαθέτουμε.
	\item \textbf{Υπόθεση $h$} Το αποτέλεσμα της εκπαίδευσης, δηλαδή η προσέγγιση της $f$, όπως φαίνεται στο Σχήμα \ref{fig:terminology}. Στο παράδειγμά μας είναι μια νοητή γραμμή, η οποία χωρίζει το δισδιάστατο χώρο των χαρακτηριστικών σε δύο υποχώρους.
	\item \textbf{Μοντέλο Εκπαίδευσης} Προκειμένου να πραγματοποιήσουμε προβλέψεις σε άγνωστα δεδομένα, χρειαζόμαστε ένα μοντέλο, μία μαθηματική διαδικασία, η οποία έχει παραμετροποιηθεί πάνω στο συγκεκριμένο πρόβλημα και λαμβάνοντας τα χαρακτηριστικά ενός νέου δεδομένου μπορεί να δώσει τη κλάση του. Το μοντέλο αποτελείται από δύο συστατικά:
	\begin{itemize}
		\item \textbf{Σετ υπόθεσης $H = \{h\}$} Κάθε μοντέλο επιχειρεί να προσεγγίσει τη συνάρτηση-στόχο με διαφορετικό τρόπο. Το σετ υπόθεσης περιέχει όλες τις πιθανές υποθέσεις, που μπορούν να προκύψουν από ένα μοντέλο. Κάθε διαφορετική υπόθεση αντιστοιχεί σε διαφορετική ρύθμιση κάποιας παραμέτρου του μοντέλου και επιτελεί διαφορετική πρόβλεψη για τα δεδομένα. Είδη μοντέλων αποτελούν τα τεχνητά νευρωνικά δίκτυα (Artificial neural networks-ANN), οι μηχανές διανυσματικής στήριξης (Support vector machines-SVM) κτλ.
		\item \textbf{Αλγόριθμος μάθησης} Ανάλογα με το μοντέλο που έχουμε επιλέξει, υπάρχει πληθώρα αλγορίθμων, οι οποίοι επιτελούν τη διαδικασία της μάθησης, προσπαθώντας να βελτιστοποιήσουν τις παραμέτρους της υπόθεσης. Για παράδειγμα οι νευρώνες (perceptrons) χρησιμοποιούν τον αλγόριθμο PLA, τα \gls{ANN} τον αλγόριθμο οπισθοδιάδοσης (backpropagation) κτλ.    
	\end{itemize}
\end{itemize}

 \begin{figure}[!htb] 	
 	\centering
 	\scalebox{.65} {
 	\begin{tikzpicture} 	
 	\node[block, align = center, minimum width = 3 cm] (A) at (0,0) {\makecell{Συνάρτηση-στόχος \\ $f: X \rightarrow Y$}};
 	\node[block, align = center, minimum width = 3 cm] (B) at ([down] A)  {\makecell{Παραδείγματα Εκπαίδευσης} \\ $(x_1, y_1), \cdots, (x_n, y_n)$};
 	\draw[->, thick] (A) to (B);
 	\node[block, ellipse, minimum width=3cm, align = center] (D) at ([downright] B) {\makecell{Αλγόριθμος Μάθησης} \\ $A$};
 	\draw [->, thick] (B)  to [out=-100,in=-180]  (D.west);
 	\node[block, align = center, minimum width = 3 cm] (C) at (0,0) at ([yshift = -12em] B) {\makecell{Σετ-Υπόθεσης \\ $H$}};
 	\draw [->, thick] (C.north)  to [out=80,in=-180]  (D.west);
 	\node[block, align = center, minimum width = 3 cm] (E) at (0,0) at ([right] D) {\makecell{Τελική Υπόθεση \\ $h \approx f$}};
 	\draw[->] (D) -- (E);
 	\draw[thick,dotted] ($(C.south west)+(-0.5,-0.4)$) rectangle ($(D.north east)+(1,+0.5)$) node[pos=.75, yshift = -2.6cm] {Moντέλο Εκπαίδευσης};
 	\end{tikzpicture}
 }
 	\caption[Συστατικά Μηχανική Μάθησης]{Συστατικά Μηχανικής Μάθησης: Στόχος της παραγωγής ενός μοντέλου εκπαίδευσης είναι η προσέγγιση, μέσω της τελικής υπόθεσης, της συνάρτησης-στόχου , για την οποία το μοντέλο λαμβάνει πληροφορία μέσω των παραδειγμάτων. (Το σχήμα προέρχεται από τη σειρά διαλέξεων~\footnote{http://work.caltech.edu/telecourse.html})}
 \end{figure}
\subsection{Η διαδικασία της μηχανικής μάθησης}
Η παρατήρηση της διαδικασίας εφαρμογής μηχανικής μάθησης σε ένα πραγματικό πρόβλημα εξηγεί γιατί οι ειδικοί σε αυτό τον τομέα χρειάζονται ένα πλούσιο, ετερογενές επιστημονικό υπόβαθρο, εμπειρία και εφευρετικότητα. Αποτελείται από διάφορα στάδια, που αλληλοεπηρεάζονται και με βάση την αξιολόγηση επαναλαμβάνονται κατά βούληση στη διάρκεια της μάθησης.

\begin{minipage}[c]{0.48\textwidth}
		\resizebox{0.92\textwidth}{!}{
	\begin{tikzpicture}[node distance = 2cm]
	% Place nodes
	\node [cloud] (problem) {Πρόβλημα};
	\node [block_flow, below of=problem] (data) {\makecell{Συλλογή\\ και καθαρισμός\\ δεδομένων}};
	\node [block_flow, below of=data] (preprocess) {\makecell{Προεπεξεργασία \\ δεδομένων}};
	\node [block_flow, below of=preprocess, node distance = 2.5cm] (split) {\makecell{Διαχωρισμός\\ σε σετ εκπαίδευσης,\\ επικύρωσης και ελέγχου}};
	\node [block_flow, below of=split, node distance = 2.5cm] (selection) {\makecell{Επιλογή\\ αλγορίθμου\\ μάθησης}};
	\node [block_flow, below of=selection] (training) {\makecell{Εκπαίδευση \\ μοντέλου}};
	\node [block_flow, left of=training, node distance=3cm] (tuning) {\makecell{Ρύθμιση\\ υπερπαραμέτρων}};
	\node [block_flow, below of=training] (evaluation) {\makecell{Αξιολόγηση \\στο σετ\\ επιβεβαίωσης}};
	\node [decision, below of=evaluation] (decide) {OK?};
	\node [block_flow, right of=decide, node distance=3cm] (stop) {\makecell{Αξιολόγηση\\ στο σετ \\ελέγχου}};
	% Draw edges
	\path [line] (problem) -- (data);
	\path [line] (data) -- (preprocess);
	\path [line] (preprocess) -- (split);
	\path [line] (split) -- (selection);
	\path [line] (selection) -- (training);
	\path [line] (training) -- (evaluation);
	\path [line] (evaluation) -- (decide);
	\path [line] (decide)  -- node [anchor=south] {ΝΑΙ} (stop);
	\path [line] (tuning) -- (training);
	\path [line] (decide) -| node [anchor=east] {ΟΧΙ} (tuning);	
	\end{tikzpicture}	
}
\captionsetup{width=0.8\textwidth}
\captionof{figure}[Η διαδικασία της μηχανικής μάθησης]{Η διαδικασία της μηχανικής μάθησης, βασισμένη στην περιγραφή των \citet{Kotsiantis:2007:SML:1566770.1566773}.}
\end{minipage}%
\begin{minipage}{0.48\textwidth}
	\paragraph{Συλλογή και καθαρισμός δεδομένων} Η επίλυση ενός προβλήματος απαιτεί την ύπαρξη σχετικών δεδομένων, τα οποία συνήθως πρέπει να καθαριστούν από αγνοούμενες τιμές και θόρυβο. 
	\paragraph{Προεπεξεργασία} Υπάρχουν διάφορες ενέργειες που μπορούν να εφαρμοστούν στα δεδομένα, με βάση τις ιδιαιτερότητες που παρουσιάζουν, ώστε να εξασφαλιστεί η καλή λειτουργία των αλγορίθμων μηχανικής μάθησης και εν γένει η καλή απόδοση του μοντέλου. Παραδείγματα αποτελούν η αφαίρεση αγνοούμενων τιμών και η κανονικοποίηση.
	\paragraph{Διαχωρισμός σε σετ εκπαίδευσης, αξιολόγησης και ελέγχου} Είναι αναγκαία η ύπαρξη δύο σετ δεδομένων, ανεξάρτητων από το σετ εκπαίδευσης, αλλά στατιστικά συσχετισμένων με αυτό (καθώς έχουν προκύψει από την ίδια άγνωστη συνάρτηση): το σετ αξιολόγησης, που θα χρησιμοποιηθεί για την επίτευξη της βέλτιστης παραμετροποίησης του μοντέλου  και το σετ ελέγχου, το οποίο αποδεικνύει πόσο καλά δουλεύει το μοντέλο σε άγνωστα δεδομένα.
    \paragraph{Εκπαίδευση μοντέλου} Απαιτεί την επιλογή ενός αλγορίθμου μάθησης και την παραμετροποίησή του, ώστε να παραχθεί το τελικό μοντέλο.
	\paragraph{Αξιολόγηση} Αξιολογείται η ποιότητα του μοντέλου μέσω της εφαρμογής του στο σετ ελέγχου και του υπολογισμού μετρικών, που επιλέγονται με βάση της φύση του προβλήματος.
\end{minipage}
\section{Τεχνικές Μηχανικής Μάθησης}
Σε αυτήν την ενότητα αναλύουμε καθιερωμένες τεχνικές μηχανικής μάθησης διαχωρίζοντάς τες ως προς το στάδιο του πειράματος, στο οποίο εμφανίζονται.
\subsection{Προεπεξεργασία} Σε αυτό το στάδιο ο αναλυτής οφείλει να αναγνωρίζει παθογένειες των δεδομένων, οι οποίες θα επηρεάσουν αρνητικά τη λειτουργία του αλγορίθμου μάθησης. Η βιβλιογραφία προσφέρει πληθώρα ετερογενών μεθοδολογιών, όπως η αναγνώριση ακατάλληλων τιμών που προέκυψαν κατά τη συλλογή των δεδομένων, η οπτικοποίηση του πληροφοριακού περιεχομένου των χαρακτηριστικών και ο μετασχηματισμός τους σε χρησιμότερες μορφές.  
\subsubsection{Ανάλυση κυρίαρχων συνιστωσών}
Η τεχνική αυτή προέρχεται από τη γραμμική άλγεβρα και εφαρμόζεται με στόχο την εξαγωγή χρήσιμων χαρακτηριστικών σε προβλήματα μηχανικής μάθησης. Ανήκει στην ομάδα των μεθόδων φιλτραρίσματος, οι οποίες εφαρμόζονται στο σετ δεδομένων πριν την εκπαίδευση προκειμένου να "φιλτραριστούν" ανεπιθύμητα χαρακτηριστικά του. Το όνομά της προδίδει τη λειτουργία της: την εύρεση των κυρίαρχων συνιστωσών στα δεδομένα.

Τα δεδομένα σε ένα πρόβλημα ταξινόμησης αποτελούνται από τα χαρακτηριστικά και την κλάση πρόβλεψης. Γεωμετρικά, μπορούμε να αντιληφθούμε τα χαρακτηριστικά ως διανύσματα-βάσεις και τις τιμές κάθε παραδείγματος ως τις προβολές σε αυτή τη βάση. Σκοπός της ανάλυσης κυρίαρχων συνιστωσών είναι να βρει μια νέα βάση για τα δεδομένα, στην οποία αυτά θα περιγράφονται "καλύτερα". Αν λοιπόν τα αρχικά μας δεδομένα βρίσκονται στον πίνακα Χ, τότε αρκεί να βρούμε έναν πίνακα μετασχηματισμού P που θα μας μεταφέρει στη νέα βάση, δηλαδή:
\begin{equation}
 Y=P X
\end{equation}
Ο πίνακας P ορίζεται με τέτοιο τρόπο ώστε να αντιμετωπιστούν δύο παθογένειες των δεδομένων: ο θόρυβος και η περίσσεια πληροφορίας. Και τα δύο αυτά προβλήματα σχετίζονται άμεσα με την έννοια της ετεροσυσχέτισης: ο μεν θόρυβος είναι εξ ορισμού ασυσχέτιστος με όλα τα χαρακτηριστικά, η δε περίσσεια πληροφορίας ποσοτικοποιείται μέσω της ετεροσυσχέτισης μεταξύ των χαρακτηριστικών. Ο πίνακας ετεροσυσχέτισης των αρχικών δεδομένων ορίζεται ως:
\begin{equation} 
S_X=\frac{1}{n-1} X X^T
\end{equation}
Προκύπτει λοιπόν μία αναγκαιότητα για τα μετασχηματισμένα δεδομένα Y: ο πίνακας ετεροσυσχέτισής τους οφείλει να είναι διαγώνιος, δηλαδή κάθε χαρακτηριστικό να συσχετίζεται μόνο με τον εαυτό του. Ο πίνακας που επιθυμούμε να διαγωνοποιήσουμε είναι λοιπόν:
\begin{equation} 
\begin{split}
S_Y & = \frac{1}{n-1} Y Y^T \\
& = \frac{1}{n-1} (PX)(PX)^T \\
& = \frac{1}{n-1} PXX^TP^T\\
& = \frac{1}{n-1} P(XX^T)P^T\\
& = \frac{1}{n-1} PAP^T
\end{split}
\end{equation}
όπου $A=XX^T$.

Σύμφωνα με τη θεωρία της γραμμικής άλγεβρας, ένας πίνακας Α διαγωνοποιείται  με τη βοήθεια ενός πίνακα, κάθε στήλη του οποίου είναι ένα ιδιοδιάνυσμα του Α, δηλαδή:
\begin{equation} 
A=EDE^T
\end{equation} 
όπου ο D είναι ένας διαγώνιος πίνακας και Ε ένας πίνακας με στήλες τα ιδιοδιανύσματα του Α. 

Αν λοιπόν επιλέξουμε τον πίνακα P, έτσι ώστε κάθε γραμμή του να είναι ιδιοδιάνυσμα του A, τότε πετυχαίνουμε:
\begin{equation} 
\begin{split}
S_Y & = \frac{1}{n-1} PAP^T \\
& = \frac{1}{n-1} P(P^TDP)P^T \\
& = \frac{1}{n-1} (PP^T)D(PP^T)\\
& = \frac{1}{n-1}(PP^{-1})D(PP^{-1})\\
& = \frac{1}{n-1} D
\end{split}
\end{equation} 
δηλαδή ο πίνακας Υ έχει διαγώνιο πίνακα ετεροσυσχέτισης και μπορούμε να πούμε πως οι κυρίαρχες συνιστώσες είναι οι γραμμές του P, δηλαδή τα ιδιοδιανύσματα του X και οι διαγώνιες τιμές του πίνακα $S_Y$ είναι η διακύμανση κατά μήκος των κυρίαρχων συστατικών.

Συνήθως κατά την εξαγωγή χαρακτηριστικών προσπαθούμε να απλοποιήσουμε την περιγραφή των δεδομένων διατηρώντας όσο το δυνατόν περισσότερη πληροφορία. Έτσι, μετά την εφαρμογή της ανάλυσης κυρίαρχων συνιστωσών μπορούμε να επιλέξουμε να κρατήσουμε τα διανύσματα που μας δίνουν ένα ικανοποιητικό μέρος της διακύμανσης, συνήθως το $ 97\% -98\% $. Σε εφαρμογές που χαρακτηρίζονται από μεγάλη διαστασιμότητα στα δεδομένα, όπως μηχανικής όρασης, αυτή η μικρή απώλεια πληροφορίας μπορεί να μειώσει τα χαρακτηριστικά κατά εκατοντάδες.

\subsubsection{Μετασχηματισμός Box-Cox}
Στη διάρκεια ενός πειράματος μηχανικής μάθησης ανακύπτει συχνά η ανάγκη εξασφάλισης κανονικής κατανομής για ένα πληθυσμό. Παραδείγματος χάριν κατά την εκπαίδευση μοντέλων παλινδρόμησης η κανονικότητα των υπολειπόμενων τιμών (residuals) αποτελεί προϋπόθεση εγκυρότητας του μοντέλου. Την ανάγκη αυτή ικανοποιεί η οικογένεια των μετασχηματισμών ισχύος (power transformations), ένας εκ των οποίων είναι ο μετασχηματισμός Box-Cox. Εισήχθη από τους \citet{10.2307/2984418} και ορίζεται ως

\begin{equation}
y^{'}=
\begin{cases}
\frac{y^{\lambda} -1}{\lambda} &  \lambda \neq 0\\
\log{y} & \lambda = 0
\end{cases}
\end{equation} 

Προκειμένου να επιλεχθεί το $\lambda$, το οποίο οδηγεί στη βέλτιστα κανονική κατανομή γίνεται χρήση της ιδιότητας των Q-Q (Quartile-Quartile) διαγραμμάτων να απεικονίζουν την κανονικότητα ενός πληθυσμού. Πρόκειται για διαγράμματα διασποράς των σημείων:

\begin{equation}
\Big( \Phi^{-1} \big(\frac{i-0.5}{n} \big), x_{i} \Big)
\end{equation} 
 
όπου $\Phi^{-1}$ η αντίστροφη συνάρτηση αθροιστικής κατανομής της κανονικής κατανομής και $i$ το $i$-oστό ταξινομημένο σημείο του πληθυσμού. Η παρατήρηση γραμμικότητας σε ένα τέτοιο διάγραμμα αποτελεί απόδειξη κανονικότητας. Επομένως, ως $\lambda$ του μετασχηματισμού Box-Cox επιλέγεται αυτό που οδηγεί σε μέγιστο συντελεστή συσχέτισης μεταξύ των σημείων του Q-Q διαγράμματος.

	\begin{figure}[!htb]
		\begin{minipage}{0.45\textwidth}
\resizebox{\textwidth}{5cm}{
		\begin{tikzpicture}	
	\begin{axis}[xlabel= Θεωρητικά ποσοστημόρια,ylabel= Ποσοστημόρια δείγματος,]
	\addplot[
	visualization depends on={\thisrow{color}\as\myvalue},
	scatter/classes={
		1={mark=*,black}
	},
	scatter, only marks,
	scatter src=explicit symbolic,
	]
	table[x=x,y=y,meta=color]
	{data/qq.dat};
	\end{axis}
	\end{tikzpicture}}
	\caption[Διάγραμμα Quantile-Quantile]{Ένα διάγραμμα διασποράς των πραγματικών τεταρτημορίων ενός πληθυσμού με τα τεταρτημόρια κανονικής κατανομής. Η διαπίστωση γραμμικότητας σε αυτό το διάγραμμα αποτελεί ένδειξη κανονικότητας της κατανομής.}	
\end{minipage} \qquad
\begin{minipage}{0.45\textwidth}
\resizebox{\textwidth}{5cm}{
	\begin{tikzpicture}[
	declare function={gamma(\z)=
		(2.506628274631*sqrt(1/\z) + 0.20888568*(1/\z)^(1.5) + 0.00870357*(1/\z)^(2.5) - (174.2106599*(1/\z)^(3.5))/25920 - (715.6423511*(1/\z)^(4.5))/1244160)*exp((-ln(1/\z)-1)*\z);},
	declare function={gammapdf(\x,\k,\theta) = (\x)^(\k-1)*exp(-\x/\theta) / (\theta^\k*gamma(\k));}
	]	
	\begin{axis}[ymin = 0,xlabel= λ,ylabel= Συντελεστής συσχέτισης,]
	\addplot [smooth, domain=0:20, black] {gammapdf(x,9,0.5)};
	\addplot +[dashed,mark = none , black] coordinates { (4.1,0)  (4.1,0.275)};
	\end{axis}
	\end{tikzpicture}}
	\caption[Επιλογή $\lambda$ Box-Cox μετασχηματισμού]{Η επιλογή του $\lambda$ που βελτιστοποιεί το συντελεστή συσχέτισης του διαγράμματος Q-Q συνεπάγεται το μετασχηματισμό στη βέλτιστα κανονική κατανομή και χρησιμοποιείται στο μετασχηματισμό Box-Cox.}

\end{minipage}
\end{figure}
	
\subsection{Εκπαίδευση}
Πρωταρχική επιλογή κατά την εκπαίδευση ενός μοντέλου ταξινόμησης είναι αυτή του αλγορίθμου μάθησης. Ο αναλυτής δεδομένων έχει στη διάθεσή του ετερογενείς αλγορίθμους, όπως o k-κοντινότερος γείτονας, οι μηχανές διανυσματικής στήριξης, o απλοϊκός bayesian ταξινομητής (Naive Bayes), η Λογιστική Παλινδρόμηση (Logistic Regression), οι οποίοι αναλύονται στα Παραρτήματα \ref{appendix:knn, appendix:Svm, appendix:NBayes, appendix:LReg} αντίστοιχα. Μία τεχνική που ενσωματώνεται σε έναν αλγόριθμο μάθησης προκειμένου να αποφευχθεί το πρόβλημα της υπερ-προσαρμογής είναι αυτή της κανονικοποίησης (Παράρτημα \ref{appendix:Reg}). Συνοπτικά θα αναφέρουμε ότι το πρόβλημα αυτό προκύπτει όταν το μοντέλο παραμετροποιείται τόσο καλά στη πρόβλεψη του σετ εκπαίδευσης ώστε να προβλέπει και θόρυβο εγγενή στα παραδείγματα, με αποτέλεσμα να έχει μειωμένη απόδοση σε άγνωστα δεδομένα.

\subsubsection{Επιλογή χαρακτηριστικών} \label{section:selection}
Σε αυτό το στάδιο θα αναλύσουμε τη δυνατότητα να εκπαιδεύσουμε το μοντέλο μας με διαφορετικά υποσύνολα των χαρακτηριστικών και να αξιολογήσουμε τις ακρίβειες των διαφορετικών μοντέλων, ώστε να συμπεράνουμε ποια χαρακτηριστικά συνεισφέρουν σίγουρα στην πρόβλεψη. Οι μέθοδοι που το επιχειρούν αυτό λέγονται wrapper, επειδή εμπλέκουν  τη διαδικασία της εκπαίδευσης και είναι πιο αποδοτικοί από τις μεθόδους επιλογής χαρακτηριστικών που είδαμε κατά την προεπεξεργασία, αποκαλούμενες μέθοδοι φιλτραρίσματος, καθώς λαμβάνουν αποφάσεις πολύ πιο συνειδητά.

Στο Σχήμα \ref{fig:wrapper} βλέπουμε πώς οι μέθοδοι αυτοί διαλέγουν διαδοχικά ένα υποσύνολο των χαρακτηριστικών, εκπαιδεύουν ένα μοντέλο, το αξιολογούν και στη συνέχεια παραδίδουν το μοντέλο με την καλύτερη απόδοση και τα χαρακτηριστικά που επέλεξαν. Είναι σημαντικό πως κατά την επαναληπτική διαδικασία της επιλογής χαρακτηριστικών, η εκπαίδευση και η αξιολόγηση γίνεται σε 2 διαφορετικά υποσύνολα, το σετ εκπαίδευσης και το σετ επικύρωσης.

\begin{figure}[!htb]
	\begin{minipage}{0.45\textwidth}
	%	\resizebox{\textwidth}{5cm}{
			\begin{tikzpicture}	
			\node[block, align = center, text width=2.5cm, text centered, minimum width = 2 cm] (A) at (0,0) {Aναζήτηση υποσυνόλου Χαρακτηριστικών};
			\node[block, align = center,text width=2.5cm, text centered, minimum width = 2 cm] (B) at ([xshift=10em, yshift=-4em] A)  {Αξιολόγηση σετ χαρακτηριστικών};
			\node[block, align = center,text width=2.5cm, text centered, minimum width = 2 cm] (C) at ([xshift=-10em, yshift=-4em] B)  {Αλγόριθμος μάθησης};
			\draw[->, thick] (A) to (C);
			\draw[->, thick] (C) -| (B);
			\draw[->, thick] (B) |- (A);	
			\end{tikzpicture}
%		}
		\caption[Μέθοδος wrapper για επιλογή χαρακτηριστικών]{Μέθοδος wrapper για επιλογή χαρακτηριστικών: σε κάθε επανάληψη γίνεται επιλογή ενός υποσυνόλου χαρακτηριστικών, το μοντέλο εκπαιδεύεται και η απόδοσή του χρησιμοποιείται για την επιλογή του επόμενου υποσυνόλου.}
		\label{fig:wrapper}
	\end{minipage} \qquad
	\begin{minipage}{0.45\textwidth}
%		\resizebox{\textwidth}{5cm}{		
			\begin{tikzpicture}	
			\node[block, align = center, text width=2.5cm, text centered, minimum width = 2 cm] (A) at (0,0) {Αρχικό σύνολο χαρακτηριστικών};
			\node[block, align = center, text width=2.5cm, text centered, minimum width = 2 cm] (B) at ([down] A)  {Επιλογή υποσυνόλου χαρακτηριστικών};
			\node[block, align = center,text width=2.5cm, text centered,minimum width = 2 cm] (C) at ([xshift=10em] B)  {Αλγόριθμος μάθησης};
			\draw[->, thick] (A) to (B);
			\draw[->, thick] (B) to (C);	
			\end{tikzpicture}
%		}
		\caption[Μέθοδος φιλτραρίσματος για την επιλογή χαρακτηριστικών]{Μέθοδος φιλτραρίσματος για την επιλογή χαρακτηριστικών: γίνεται επιλογή ενός υποσυνόλου με βάση κάποιες ιδιότητες των χαρακτηριστικών, όπως η συσχέτισή τους στην Ανάλυση Κυρίαρχων Συνιστωσών.}
	\end{minipage}
\end{figure}

Η λογική με την οποία επιλέγονται τα υποσύνολα που θα δοκιμαστούν ακολουθεί συνήθως μία από δύο διαφορετικές συλλογιστικές:
\begin{itemize}
	\item \textbf{προς τα εμπρός επιλογή.} Ξεκινά με ένα άδειο σύνολο και προσθέτει διαδοχικά χαρακτηριστικά που μειώνουν το σφάλμα ταξινόμησης μέχρι καμία προσθήκη να μη το βελτιώνει.
	\item \textbf{προς τα πίσω επιλογή.} Ξεκινά με όλα τα χαρακτηριστικά και αφαιρεί διαδοχικά χαρακτηριστικά που μειώνουν το σφάλμα ταξινόμησης μέχρι καμία αφαίρεση να μη το βελτιώνει.
\end{itemize}
Τα βασικά μειονεκτήματα αυτών των μεθόδων είναι πως είναι χρονοβόρα και μπορεί να οδηγήσουν σε υπερ-προσαρμογή.

\subsubsection{Συνάθροιση μοντέλων}
Στο σημείο αυτό θα γνωρίσουμε μια οικογένεια τεχνικών, που στοχεύουν στη βελτίωση της μηχανικής μάθησης, καθώς αποτελούν επιπρόσθετο κομμάτι της διαδικασίας και όχι πρωταρχικό της συστατικό. Η ιδέα που κρύβεται από πίσω τους, αν και αρχαία, ανατρέπει την παραδοσιακή προσέγγιση της μηχανικής μάθησης και προσδίδει περισσότερη σχεδιαστική ελευθερία στο στάδιο της εκπαίδευσης ενός μοντέλου.

Μία από τις βασικές αρχές της μηχανικής μάθησης αποτελεί το "ξυράφι του Όκαμ": Δεδομένου ενός προβλήματος, μεταξύ ανταγωνιζομένων λύσεων επιλέγουμε αυτήν που απαιτεί τις λιγότερες υποθέσεις. Αυτή η αρχή ερμηνεύεται ως εξής: αν διαθέτω ετερογενείς και σωστές λύσεις σε ένα πρόβλημα, τότε θα προτιμήσω την απλούστερη. Στον τομέα της μηχανικής μάθησης αυτό αντιστοιχεί στην επιλογή της απλούστερης υπόθεσης, δηλαδή αυτής που προέκυψε από το μοντέλο με τις λιγότερες
παραμέτρους και την απλούστερη προεπεξεργασία, μεταξύ υποθέσεων με παρόμοια ακρίβεια. Το συμπέρασμα φαντάζει λογικό: αν έχουμε βρει ένα απλό μοντέλο, που περιγράφει τη συνάρτηση-στόχο γιατί να διακινδυνέψουμε με ένα πιο απαιτητικό, χρονικά και υπολογιστικά, δυσνόητο και ευάλωτο σε υπερ-προσαρμογή μοντέλο;

Στον αντίποδα αυτής της επιχειρηματολογίας βρισκόταν ο Επίκουρος: "αν έχω βρει πολλές ερμηνείες για κάποιο φαινόμενο, γιατί να μην τις λάβω όλες υπόψιν μου, ώστε να έχω μια πιο ολοκληρωμένη αντίληψη"; Με την παραδοχή πως δεν υπάρχουν αυθεντίες, αλλά ειδικοί, ο συνδυασμός των απόψεων ειδικών σε διαφορετικούς τομείς ενός προβλήματος, μπορεί να οδηγήσει σε μια πιο εξισορροπημένη και βέλτιστη λύση. Αντιστοίχως, το βελτιστοποιημένο μοντέλο με το οποίο έχουμε επιλύσει ένα πρόβλημα ταξινόμησης δε συνιστά εγγυημένα καλή λύση, καθώς υπόκειται σε περιορισμούς, που δεν εμφανίζονται σε άλλα μοντέλα.

Υπάρχουν διάφορες τεχνικές με τις οποίες μπορούμε να συνδυάσουμε τη γνώση διαφορετικών μοντέλων με σκοπό η ακρίβεια της συνισταμένης γνώσης να είναι καλύτερη από το βέλτιστο μοντέλο που επιτεύχθηκε με τη χρήση ενός αλγορίθμου.

\begin{itemize}
	\item \textbf{Bootstrap- aggregating} Η τεχνική αυτή, που συνήθως αποκαλείται \textit{bagging}, συνιστά τον απλούστερο τρόπο συνάθροισης: Από τα παραδείγματα εκπαίδευσης, λαμβάνουμε Κ υποσύνολα με n στοιχεία το καθένα, δειγματοληπτώντας με αντικατάσταση. Για κάθε διαφορετικό δείγμα εκπαιδεύουμε ένα μοντέλο με έναν αλγόριθμο ομαδοποίησης, για παράδειγμα με ένα δέντρο ταξινόμησης. Όταν θέλουμε να προβλέψουμε την κλάση ενός νέου στοιχείου, χρησιμοποιούμε τα Κ μοντέλα και τελικά προβλέπουμε την κλάση που επέλεξε η πλειοψηφία. Ο λόγος για τον οποίο επιλέξαμε τα δέντρα ως παράδειγμα δεν είναι τυχαίος: η τεχνική αυτή χρησιμοποιείται κυρίως για μοντέλα που επηρεάζονται από την τυχαιότητα των δεδομένων εκπαίδευσης, γεγονός που εξασφαλίζεται με την τυχαία δειγματοληψία.
	\item \textbf{Boosting} Η προηγούμενη τεχνική θα μπορούσε να χαρακτηριστεί ως naive, καθώς υποθέτει πως τα διαφορετικά μοντέλα παρουσιάζουν μη αλληλεπικαλυπτόμενες αδυναμίες και άρα απλά συνδυάζοντάς τα θα καλύψουμε ικανοποιητικά όλους τους τύπους εισόδου. Η υπόθεση αυτή δεν είναι ωστόσο ρεαλιστική, καθώς τα μοντέλα τείνουν να δυσκολεύονται σε παρόμοιες περιπτώσεις. Η τεχνική \textit{boosting} ακολουθεί επίσης τη λογική εκπαίδευσης Κ μοντέλων, τα οποία ωστόσο δεν είναι ανεξάρτητα: κάθε μοντέλο δίνει περισσότερη βαρύτητα στην ταξινόμηση παραδειγμάτων, τα οποία τα προηγούμενα μοντέλα απέτυχαν να ταξινομήσουν σωστά. Επίσης, η ψήφος των μοντέλων δεν είναι ισοδύναμη, αλλά ενισχύεται για τα ακριβέστερα μοντέλα.
	\item \textbf{Stacked generalization} Η ψηφοφορία των διαφορετικών μοντέλων γίνεται δυσκολότερη, όταν έχουν εκπαιδευθεί με τη χρήση διαφορετικών αλγορίθμων. Διαφοροποιήσεις ως προς τις προϋποθέσεις, τη λειτουργία και το είδος της εξόδου των αλγορίθμων οδηγούν σε μη-συγκρίσιμα  και διαφορετικής ποιότητας αποτελέσματα. Η τεχνική αυτή, που αποκαλείται εν συντομία \textit{stacking}, δίνει λύση σε αυτό το πρόβλημα εισάγοντας την έννοια του μετα-μοντέλου εκπαίδευσης. Σε πρώτο στάδιο τα μοντέλα εκπαιδεύονται και παράγεται η πρόβλεψη για κάθε παράδειγμα. Το δεύτερο στάδιο, που αποτελεί το μετα-μοντέλο, παίρνει ως είσοδο την πρόβλεψη κάθε μοντέλου και την πραγματική
	κλάση για κάθε παράδειγμα και εκπαιδεύει ένα νέο μοντέλο μηχανικής μάθησης, που θα αποφασίσει πώς θα συνδυάσει τα επιμέρους ώστε να επιτύχει την καλύτερη ακρίβεια.
\end{itemize}

\subsection{Αξιολόγηση}
Είδαμε πως τόσο κατά τη ρύθμιση του μοντέλου στη διάρκεια της εκπαίδευσης, όσο και για την τελική αξιολόγηση του μοντέλου για τη διαπίστωση της ικανότητάς του να γενικεύει χρειαζόμαστε δύο ανεξάρτητα σετ: ένα στο οποίο θα γίνεται η εκπαίδευση και ένα στο οποίο θα γίνεται η αξιολόγηση του μοντέλου. Φυσικά τα δεδομένα μας δίνονται ενιαία και ο τρόπος με τον οποίο θα διαχωριστούν αποτελεί σχεδιαστική επιλογή. O ειδικός οφείλει να συμβιβαστεί μεταξύ δύο σκοπών: τη
χρήση όσο το δυνατόν μεγαλύτερου σετ εκπαίδευσης, για να παραχθεί ένα πιο "σοφό" μοντέλο, αλλά και σετ ελέγχου, ώστε η γενίκευση να είναι εγγυημένη, λαμβάνοντας υπόψιν το πεπερασμένο του σετ δεδομένων και του διαθέσιμου χρόνου.
\subsubsection{Μέθοδοι} \label{section:eval}
\paragraph{Hold out} Πρόκειται για την απλούστερη τεχνική: αναθέτουμε ένα μέρος των δεδομένων για εκπαίδευση και τα υπόλοιπα τα αφήνουμε στην άκρη για αξιολόγηση. Οι συνήθεις αναλογίες είναι $80\%-20\%$ και $75\%-25\%$ για εκπαίδευση και αξιολόγηση αντίστοιχα. Αν και γρήγορη, η τεχνική αυτή δεν προτιμάται, καθώς δεν εγγυάται την αξιοπιστία του αποτελέσματος και συρρικνώνει πολύ το σετ εκπαίδευσης.
\paragraph{Leave one out} Με την τεχνική αυτή μεγιστοποιούμε το μέγεθος των δύο σετ εις βάρος του χρόνου της μάθησης: κάθε φορά εκπαιδεύουμε το μοντέλο με όλα τα δεδομένα εκτός από ένα και το αξιολογούμε σε αυτό, επαναλαμβάνοντας τη διαδικασία τόσες φορές όσα είναι τα δεδομένα μας.
\paragraph{k-fold cross-validation}Αυτή είναι η συνηθέστερη τεχνική, καθώς εξασφαλίζει μικρούς χρόνους μάθησης και αξιόπιστο αποτέλεσμα τόσο από πλευρά εκπαίδευσης όσο και από πλευρά αξιολόγησης. Τα δεδομένα χωρίζονται σε k υποσύνολα, το μοντέλο εκπαιδεύτει με τα $k-1$ και αξιολογείται με το εναπομείναν. Η διαδικασία επαναλαμβάνεται k φορές, ώστε όλα τα υποσύνολα να χρησιμοποιηθούν μία φορά για
αξιολόγηση. Τελικά η απόδοση του μοντέλου υπολογίζεται ως ο μέσος όρων των επιδόσεων στα k υποσύνολα. Συνήθως το k επιλέγεται ως $10$, οπότε μιλάμε για $10$-fold cross-validation. 
\paragraph{.632 bootstrap} Η τεχνική αυτή προσπαθεί να πετύχει το στόχο του Cross-validation, με διαφορετική όμως λογική: αντί να τεμαχίζουμε το σετ εκπαίδευσης, δημιουργούμε k αντίγραφά του με τυχαία δειγματοληψία με αντικατάσταση, το καθένα από τα οποία αποτελείται από Ν στοιχεία. Αν λοιπόν το αρχικό σετ δεδομένων ήταν:
\begin{equation}
S=
\begin{bmatrix}
y_1 &  x_{11}  & \dots  &   x_{1p} \\
\vdots  & \vdots &\ddots & \vdots \\
y_N &  x_{N1}  & \dots  &   x_{Np} \\
\end{bmatrix}
\end{equation}
τότε κάθε δείγμα ορίζεται ως:
\begin{equation}
S_b=
\begin{bmatrix}
y_1^{*b} &  x_{11}^{*b}  & \dots  &   x_{1p}^{*b} \\
\vdots  & \vdots &\ddots & \vdots \\
y_N^{*b} &  x_{N1}^{*b}  & \dots  &   x_{Np}^{*b} \\
\end{bmatrix}
\end{equation}
Στη συνέχεια μπορούμε να εκπαιδεύσουμε ένα διαφορετικό μοντέλο $\bar{f}^{*b}(x)$ με κάθε δείγμα και να υπολογίσουμε το σφάλμα ως εξής:
\begin{equation}
\bar{E}_{boot}=\frac{1}{B} \frac{1}{N} \sum_{b=1}^{B} \sum_{i=1}^{N} L(y_i,\bar{f}^{*b}(x))
\end{equation}
Ο παραπάνω δείκτης είναι πολωμένος, καθώς υπάρχει η πιθανότητα δεδομένα που έχουν χρησιμοποιηθεί για την εκπαίδευση ενός μοντέλου να χρησιμοποιηθούν και για την αξιολόγησή του. Η πιθανότητα αυτή, όπως προκύπτει λόγω της τυχαίας δειγματοληψίας με αντικατάσταση είναι πολύ μεγάλη:
\begin{equation}
P[(y_i, x_i) \in S_b]= 1- (1- \frac{1}{N})^N \approx 1- e^{-1} \approx 0.632
\end{equation}
Την παθογένεια αυτή επιχειρεί να λύσει η τεχνική του leave-one-out bootstrap Cross-validation, όπου τα στοιχεία δε χρησιμοποιούνται για την αξιολόγηση ενός μοντέλου, στην εκπαίδευση του οποίου έχουν συμμετάσχει:

\begin{equation}
\bar{E}_{boot(1)}=\frac{1}{N} \sum_{i=1}^{N} \frac{1}{\abs{C^{-i}}} \sum_{b \in C^{-i}} L(y_i,\bar{f}^{*b}(x))
\end{equation}

Η παραπάνω μετρική συνεχίζει ωστόσο να είναι πολωμένη λόγω της συχνής επαναχρησιμοποίησης δεδομένων: κάθε δείγμα  περιέχει κατά μέσο όρο $0.632 \cdot N$ διαφορετικά στοιχεία, χαρακτηριστικό που θυμίζει 2-fold cross-validation.

Έτσι, προτάθηκε η συμβιβαστική λύση του .632 bootstrap():
\begin{equation}
\bar{E}^{(0.632)}= 0.368 \cdot \overline{err} + 0.632 \cdot \bar{E}_{boot(1)}
\end{equation}

όπου $\overline{err}$ είναι το σφάλμα που υπολογίζεται για τα σημεία που έχουν συμμετάσχει στην εκπαίδευση.

Αυτή η μετρική προσπαθεί να σταθμίσει τη συνεισφορά δύο αντίθετα πολωμένων όρων. Ο πρώτος αποτελεί τον απλό εκτιμητή και λειτουργεί σωστά για σημεία που δεν απέχουν καθόλου από το σετ εκπαίδευσης. Ο δεύτερος έχει υποθέσει τη μεγαλύτερη απόσταση των νέων δεδομένων από το σετ εκπαίδευσης (η πιθανότητα ένα στοιχείο να μη συμμετέχει σε ένα δείγμα είναι $0.368$).

Ο σχεδιασμός της αξιολόγησης αποτελεί βασικό στάδιο για την επιτυχή εκπαίδευση ενός μοντέλου. Η κακή σχεδίαση οδηγεί είτε στην εκπαίδευση ενός υπο\-βέλτιστου μοντέλου είτε στη λανθασμένη εκτίμηση της απόδοσής του. Όπως επισήμαναν οι \citet{10.2307/3058705} αμφισβητήσιμη είναι η ποιότητα των ερευνών που χρησιμοποιούν τα παραδείγματα ελέγχου κατά τη ρύθμιση του μοντέλου, καθώς παράγουν θετικά πολωμένες εκτιμήσεις. Οι ίδιοι συνεχίζουν υπενθυμίζοντας πως η τεχνική leave one out οδηγεί σε μοντέλα υψηλής διακύμανσης, δηλαδή αμφισβητήσιμης απόδοσης σε νέα προβλήματα, γεγονός που αποδίδεται στην ομοιότητα των σετ εκπαίδευσης (κάθε ζεύγος διαφέρει ως προς ένα παράδειγμα). Ως καλύτερη συμβιβαστική λύση προτείνεται η τεχνική k-fold cross-validation για k=10. Καθώς μικρότερες τιμές του k οδηγούν σε υποβέλτιστα μοντέλα λόγω περιορισμένων παραδειγμάτων στο σετ εκπαίδευσης και μεγαλύτερες ενσωματώνουν τα προβλήματα του leave one out, η τιμή αυτή προσφέρει μια ευριστικά καλή λύση. 
\subsubsection{Μετρικές} Σκοπός μίας μετρικής είναι η ποσοτικοποίηση της ποιότητας ενός μοντέλου. Καθώς λοιπόν η ποιότητα ορίζεται μέσω της επίτευξης ενός προσδοκώμενου στόχου, η επιλογή της μετρικής που θα χρησιμοποιηθεί για δεδομένο πρόβλημα θα εξαρτηθεί από τη φύση του.

Σε ένα πρόβλημα ταξινόμησης οι συνήθεις μετρικές προκύπτουν από τεχνικές σύνοψης της λειτουργίας του ταξινομητή, όπως ο Πίνακας Σύγχυσης και η καμπύλη ROC (Receiver Operating characteristic).

\paragraph{Πίνακας Σύγχυσης} Ο Πίνακας Σύγχυσης εισήχθη από τους \citet{Provost98onapplied}, ως μια ειδική περίπτωση πίνακα ενδεχομένων (contigency table), δηλαδή ενός πίνακα που περιγράφει την κατανομή πιθανοτήτων τυχαίων μεταβλητών. Αποτελεί τρόπο παρουσίασης της λειτουργίας ενός δυαδικού ταξινομητή συνοψίζοντας τις σωστές και λανθασμένες προβλέψεις του ως προς τις διαφορετικές κλάσεις του προβλήματος. Οι κυρίαρχες μετρικές σε τέτοια προβλήματα μπορούν να οριστούν μέσω αυτού.

\renewcommand\arraystretch{1.5}
	\setlength\tabcolsep{0pt}
	\begin{center}
		\begin{tabular}{c >{\bfseries}r @{\hspace{0.7em}}c @{\hspace{0.4em}}c @{\hspace{0.7em}}l}
			\multirow{10}{*}{\rotatebox{90}{\parbox{1.5cm}{\bfseries \centering Πραγματική κλάση}}} & &  \multicolumn{2}{c}{\bfseries Προβλεπόμενη κλάση} & \\
			 & \quad \bfseries  & \bfseries  \\
			&  & \MyBox{TP} & \MyBox{FN} &  \\[2.4em]
			&  & \MyBox{FP} & \MyBox{TN} &  \\
			&  &  &  &
		\end{tabular}
		\captionof{table}[Πίνακας Σύγχυσης Δυαδικού Ταξινομητή]{Ο Πίνακας Σύγχυσης συνοψίζει τη λειτουργία του δυαδικού ταξινομητή, ο οποίος προβλέψει μεταξύ θετικών και αρνητικών παραδειγμάτων. TP: σωστά θετικά, TN: σωστά αρνητικά, FN: λάθος αρνητικά, FP: λάθος θετικά }
		\label{fig:confmatrix}
	\end{center}

  Οι συνήθεις μετρικές που προκύπτουν από τον Πίνακα \ref{fig:confmatrix} είναι οι εξής:
\begin{align*} 
\text{1. Ακρίβεια (Accuracy)} &=  \frac{TP + T N}{T P + T N + F P + F N} \\ 
\text{2. Ανάκληση (Recall)} &=  \frac{TP}{TP + FN} \\
\text{3. Ακρίβεια (Precision)} &=  \frac{TP}{TP + FN} \\
\text{4. F-μετρική (F-measure)} &= \frac{2* (\text{Precision} + \text{Recall)}}{\text{Precision} + \text{Recall}} 
\end{align*}

\paragraph{Καμπύλη ROC} Οι καμπύλες αυτές απεικονίζουν την απόδοση ενός δυαδικού ταξινομητή για μεταβλητό κατώφλι διάκρισης (αν θεωρήσουμε ότι ο ταξινομητής είναι πιθανοτικός, τότε το κατώφλι διάκρισης ορίζει την τιμή της πιθανότητας πέρα από την οποία προβλέπεται διαφορετική κλάση). Το διάγραμμα σχηματίζεται τοποθετώντας ένα σημείο για κάθε τιμή κατωφλίου με τετμημένη την Ειδικότητα (Specificity) και τεταγμένη την Ευαισθησία (Sensitivity), οι οποίες ορίζονται ως

\begin{figure}[!htb]
	\centering
	\scalebox{0.5}{
     \input{tikz/ROC}}
     \caption[Καμπύλη ROC Δυαδικού Ταξινομητή]{Καμπύλη ROC: η γραμμή αντιστοιχεί σε τυχαίο ταξινομητή, αποτελεί δηλαδή το σημείο αναφοράς του διαγράμματος. Όσο πιο πάνω και δεξιά βρίσκεται η καμπύλη του τόσο καλύτερη η απόδοσή του, με το σημείο $(0,1)$ να αντιστοιχεί σε τέλειο ταξινομητή.}
\end{figure}

\begin{align*} 
\text{1. Ειδικότητα (Specificity)} &= \frac{TP}{T P + T N} \\ 	
\text{2. Ευαισθησία (Sensitivity)} &= \frac{FP}{FP + TN} 
\end{align*}

	 
\subsubsection{Στατιστικά τεστ υπόθεσης}Τα πειράματα ταξινόμησης απαιτούν τη στατιστική ανάλυση πληθυσμών για την εξαγωγή συμπερασμάτων. Αν θεωρήσουμε ένα σύνολο από σετ δεδομένων δυαδικής ταξινόμησης, μερικά ερωτήματα που μπορούν να προκύψουν είναι: υπάρχει κάποια στατιστική συσχέτιση μεταξύ της κλάσης και κάποιου χαρακτηριστικού για ένα συγκεκριμένο σετ δεδομένων; Ποιος αλγόριθμος παρουσιάζει γενικά καλύτερη συμπεριφορά;

Τα στατιστικά τεστ εφαρμόζονται σε πίνακες ενδεχομένων (\textit{contigency tables}) και έχουν ως στόχο της απόρριψη ή μη της μηδενικής υπόθεσης, η οποία αντιστοιχεί σε ανεξαρτησία των δεδομένων και τυχαιότητα των διαφορών που παρουσιάζονται μεταξύ διαφορετικών πληθυσμών. Οι πίνακες αυτοι είναι 1-way, 2-way ή 3-way, ενώ για την εμπλοκή περισσότερων πληθυσμών οι ερευνητές καταφεύγουν σε γενικευμένα γραμμικά μοντέλα \citep{Introduction}.

Μερικές έννοιες που σχετίζονται με τα στατιστικά τεστ είναι:
\begin{itemize}
	\item \textbf{Εναλλακτική υπόθεση (alternative hypothesis)} Προτείνεται από τον ερευνητή και χαρακτηρίζει τη στατιστική σχέση μεταξύ των δύο πληθυσμών υπό σύγκριση. Συγκρίνεται ως η εναλλακτική μιας ιδανικής μηδενικής υπόθεσης, η οποία αποκλείει οποιαδήποτε σχέση μεταξύ των δύο δειγμάτων. Στόχος του πειράματος είναι η απόρριψη της μηδενικής υπόθεσης, ενώ σε περίπτωση αποτυχίας το συμπέρασμα είναι η αδυναμία απόρριψης της μηδενικής υπόθεσης και όχι η επιβεβαίωση της εναλλακτικής.
	\item \textbf{Στατιστική σημασία (statistical significance)} Το πείραμα έχει στατιστική σημασία, όταν η σχέση μεταξύ των δειγμάτων είναι απίθανο να προκύψει από τη μηδενική υπόθεση με βάση ένα κατώφλι πιθανότητας $\alpha$.
	\item \textbf{Στατιστική του τεστ} Πρόκειται για μία στατιστική μετρική ενός δείγματος, σκοπός της οποίας είναι να ποσοτικοποιήσει χαρακτηριστικά του δείγματος, τα οποία θα βοηθήσουν στο διαχωρισμό της μηδενικής από την εναλλακτική υπόθεση.
	\item \textbf{Διάστημα εμπιστοσύνης(confidence interval)}  Προκύπτει από το κατώφλι πιθανότητας ως $1-\alpha$ και ερμηνεύεται ως εξής: Αν έχουμε $95 \%$ διάστημα εμπιστοσύνης τότε είμαστε κατά ίση πιθανότητα σίγουροι ότι η μέση τιμή του πληθυσμού (και όχι των δειγμάτων) θα κινείται σε συγκεκριμένα πλαίσια (που προκύπτουν από την κατανομή του test statistic).
	\item \textbf{p-τιμή (p-value)} Είναι η τιμή που οδηγεί στο συμπέρασμα του στατιστικού πειράματος. Αποτελεί απόδειξη κατά της μηδενική υπόθεσης και όσο χαμηλότερη είναι η τιμή του τόσο ισχυρότερη η απόρριψή της. Για δεδομένο κατώφλι πιθανότητας αρκεί να είναι μικρότερο από αυτό.
	\item \textbf{Σφάλματα τύπου Ι/ΙΙ (type I/II errors)} Η απόρριψη μιας έγκυρης μηδενικής υπόθεσης χαρακτηρίζεται ως σφάλμα τύπου Ι, ενώ η αδυναμία απόρριψης μιας άκυρης σφάλμα τύπου ΙΙ.
	\item {Ισχύς (Power)} Πρόκειται για τη πιθανότητα το τεστ να απορρίψει μια λανθασμένη μηδενική υπόθεση.
\end{itemize}

Για έναν πλήρη κατάλογο των συμβατικών τεστ που χρησιμοποιούνται στη βιβλιογραφία μπορούμε να ανατρέξουμε στο Παράρτημα \ref{appendix:Tests}.
\section{Αυτοματοποιημένη Μηχανική Μάθηση}
 Έχοντας αναλύσει μερικά από τους αλγορίθμους που προσφέρει η επιστήμη της μηχανικής μάθησης, μάλλον μας έχει δοθεί η εντύπωση πως απευθύνεται σε μία ολιγομελη κοινωνία ειδικών, που με χρόνια εμπειρίας, εξειδικευμένη έρευνα και λίγη δόση τύχης, καταφέρνει να δημιουργήσει μοντέλα μηχανικής μάθησης που λύνουν πραγματικά προβλήματα. Είναι αλήθεια πως σε κάθε στάδιο, οι σχεδιαστικές επιλογές που επηρεάζουν την απόδοση του μοντέλου,προσθέτουν στο πρόβλημα αρκετούς βαθμούς ελευθερίας και καθιστούν τη βέλτιστη επιλογή χρονοβόρα και αμφισβητήσιμη. Τα οφέλη ωστόσο που προσφέρει ένα αποδοτικό μοντέλο είναι τόσο άμεσα και το πεδίο εφαρμογών της μηχανικής μάθησης τόσο ευρύ, που η ιδέα της αυτοματοποίησης της διαδικασίας βελτιστοποίησης έχει κινητοποιήσει μια μεγάλη μερίδα ειδικών. Είναι χαρακτηριστικό
 το γεγονός ότι στη συνολική διαδικασίας της μηχανικής μάθησης, που ουσιαστικά αφορά την εύρεση του μοντέλου πρόβλεψης, το $75\%$ αφορά την προετοιμασία των δεδομένων και το $15\%$ την ανάλυση των αποτελεσμάτων. \footnote{https://indico.lal.in2p3.fr/event/2914/session/1/contribution/4/material/slides/0.pdf}
 
 Ο όρος AutoML είναι σχετικά πρόσφατος στη βιβλιογραφία και αφορά κάθε τεχνική
 αυτοματοποίησης οποιουδήποτε σταδίου της διαδικασίας της μηχανικής μάθησης. Ο Matthew Mayο \footnote{http://www.kdnuggets.com/2017/01/current-state-automated-machine-learning.html} αποτυπώνει την ουσία του AutoML ως εξέλιξη της σχέσης ανθρώπου-μηχανής:
 
 \begin{displayquote}
 \textit{Ο προγραμματισμός στοχεύει στην αυτοματοποίηση, η μηχανική μάθηση στην αυτοματοποίηση της αυτοματοποίησης και η αυτοματοποιημένη μηχανική μάθηση στην αυτοματοποίηση του να αυτοματοποιείς την αυτοματοποίηση. Δεδομένου λοιπόν ότι ο προγραμματισμός αναλαμβάνει τη διεκπεραίωση τετριμμένων καθηκόντων και η μηχανική μάθηση επιτρέπει στους υπολογιστές να εκπαιδευτούν στην καλύτερη επίλυση των καθηκόντων, το AutoML καταφτάνει για να επιτρέψει στους υπολογιστές να αυτοματοποιήσουν το αποτέλεσμα της εκπαίδευσης.}
 \end{displayquote}
 
 \subsection{Ιστορική Αναδρομή} \label{section:autohistory}
 Ο τομέας της αυτοματοποίησης της μηχανικής μάθησης βρίσκεται σε πειραματικό στάδιο, όχι όμως και σε εμβρυικό. Τα σύγχρονα, εντυπωσιακά εργαλεία που έχουν στη διάθεσή τους σήμερα οι ειδικοί, προέκυψαν από την εικοσαετή εκκόλαψη της ιδέας της αυτοματοποίησης των βασικών σταδίων της μηχανικής μάθησης. To 1995 η εταιρία Unica εισήγαγε στην αγορά το Pattern Recognition Workbench, ένα πακέτο λογισμικού
 που ενσωμάτωσε την αυτομαποίηση της ρύθμισης μοντέλων με νευρωνικά δίκτυα. Το λογισμικό Model 1 αποτέλεσε απόγονο του παραπάνω προϊόντος, καθώς το επέκτεινε και σε άλλες οικογένειες αλγορίθμων. Τα τέλη της δεκαετίας του 90 έχουν να επιδείξουν ακόμη δύο προσπάθειες: το Marketswitch, και το KXEN, εργαλεία που απευθύνονταν κυρίως στην αγορά του Marketing, παρέχοντας διεπαφές για αυτοματοποίηση των προβλεπτικών μοντέλων. Πιο πρόσφατα παραδείγματα αποτελούν οι κολοσσοί στην αγορά των πωλητών λογισμικού για στατιστικές αναλύσεις: η SAS και η IBM SPSS, που με τα προϊόντα τους SAS Rapid Modeler και IBM SPSS Modeler αντίστοιχα προσπάθησαν από το 2010 να αυτοματοποιήσουν την προ επεξεργασία των δεδομένων, παραχωρώντας ταυτόχρονα στο χρήστη λειτουργικότερες διεπαφές~\footnote{https://www.datarobot.com/blog/automated-machine-learning-short-history/}.
 
 Αν και βραχύβια, η ιστορία του AutoML μπορεί να μας διδάξει κάτι: η αρχική θεώρηση της αυτοματοποίησης της μηχανικής μάθησης ως λύτρωση  από τη χρονοβόρα και πνευματικά απαιτητική επίτευξη ενός αποτελεσματικού μοντέλου ήταν λανθασμένη. Τα εργαλεία που αντιμετώπισαν την εκπαίδευση ως ένα μαύρο κουτί, ώστε ο χρήστης να πετυχαίνει εντυπωσιακά αποτελέσματα αγνοώντας τις βασικές αρχές και λειτουργίες των αλγορίθμων, απέτυχαν κατά την εφαρμογή τους σε πραγματικά προβλήματα. Πλέον αντιλαμβανόμαστε αυτόν τον τομέα ως ένα εργαλείο στα χέρια του ειδικού, που επιταχύνει, διευκολύνει και επεκτείνει τη μηχανική μάθηση, όπως ένα  εργαλείο ρομποτικής ιατρικής στα χέρια ενός χειρούργου. 
 
 Στη συνέχεια θα αναλύσουμε κυρίαρχες τεχνικές σε δύο βασικούς τομείς της πρόσφατης βιβλιογραφίας του AutoML: της βελτιστοποίησης των υπερ-παραμέτρων αλγορίθμων μηχανικής μάθησης και της μετα-μάθησης.
 
 \subsection{Βελτιστοποίηση Υπερ-παραμέτρων} \label{section:opt}
 	Ένα βασικό στάδιο κατά την εκπαίδευση αλγορίθμων μηχανικής μάθησης είναι αυτό της επιλογής των υπερ-παραμέτρων του μοντέλου.
 	
 	Μαθηματικά το πρόβλημα μπορεί να διατυπωθεί ως εξής: σκοπός ενός πειράματος μηχανικής μάθησης είναι η εκπαίδευση ενός μοντέλου $M$, το οποίο ελαχιστοποιεί μία προκαθορισμένη συνάρτηση κόστους $L$ σε ένα σετ δεδομένων $X$. Το μοντέλο $Μ$ κατασκευάζεται από έναν αλγόριθμο μάθησης $Α$, ο οποίος παραμετροποιείται από ένα σύνολο παραμέτρων $\lambda$.
 	
 	Καταλήγουμε λοιπόν στον μαθηματικό ορισμό της εύρεσης του συνόλου των υπερ-παραμέτρων $\lambda^*$, που ορίζουν το βέλτιστο μοντέλο $M^*$
 	
 	
 	\begin{equation}
 	\label{opt}
 	\lambda^* = \argmin \left \{L(X^{(te)}; M(X^{(tr)}; \lambda)) \right \} = \argmin_{\lambda} \left \{L(\lambda; M, X^{(tr)}, L) \right \}
 	\end{equation} 
 	όπου $X^{(tr)}$ το σετ δεδομένων και $X^{(te)}$ το σετ ελέγχου.
 	
 	Αν συμπεριλάβουμε στη διατύπωση του προβλήματος και την επιλογή του βέλτιστου αλγορίθμου μηχανικής μάθησης, τότε η εξίσωση \ref{opt} μπορεί να αναδιατυπωθεί ώστε να περιλαμβάνει όλα τα $M$ μοντέλα, καθένα εκ τω οποίων έχει διαφορετικές υπερ-παραμέτρους $\lambda$. 
 	
 	\begin{equation}
 	\label{optCash}
 	\lambda^* = \argmin_{M^{j} \in M, \lambda \in \Lambda} \left \{L(X^{(te)}; M^{j}(X^{(tr)}; \lambda)) \right \}
 	\end{equation} 
 	
 	όπου $M ={M^{1}, \cdots, M^{k}}$ είναι ο χώρος των πιθανών αλγορίθμων και $ \Lambda = \Lambda^{1} \cup \cdots \cup \Lambda^{k} \cup {\lambda_r} $ o χώρος των υπερ-παραμέτρων όλων των αλγορίθμων, όπου $\lambda_r$ μία βοηθητική υπερ-παράμετρος για την εναλλαγή μεταξύ αλγορίθμων.
 	
 	Το πρόβλημα αυτό αναφέρεται ως Πρόβλημα Συνδυασμένης Επιλογής αλγορίθμου και Βελτιστοποίησης Υπερ-παραμέτρων (Combined Algorithm Selection and Hyperparameter optimization - CASH) \citep{DBLP:journals/corr/LoshchilovH16}
 	
	Μερικά χαρακτηριστικά της παραπάνω συνάρτησης είναι τα εξής:
	\begin{itemize}
		\item είναι μια συνάρτηση μαύρου κουτιού, δηλαδή περιγράφεται μόνο μέσω εισόδων-εξόδων.
		\item δεν έχουμε γνώση για τις παραγώγους της, το οποίο είναι άμεσο επακόλουθο της προηγούμενης πρότασης.
		\item είναι μη-κυρτή. 
		\item δεν εξαρτάται εξίσου από όλες τις παραμέτρους. 
		\item ο υπολογισμός της για δεδομένο $\lambda$ είναι υπολογιστικά και χρονικά απαιτητικός.
	\end{itemize}
	
	Η θεωρία της βελτιστοποίησης συναρτήσεων έχει προσφέρει ποικίλλες επιλογές στην επίλυση του υπό μελέτη προβλήματος. Eξελικτικοί αλγόριθμοι \citep{1554741}, κατάβαση κλήσης (gradient decent) \citep{wassenberg},  αλγόριθμοι βασισμένοι σε ευριστικές \citep{Nelder01011965, Huang2006}. Τα χαρακτηριστικά ωστόσο που αναφέρουμε προσδίδουν στη βελτιστοποίηση της Εξίσωσης \ref{opt} ιδιαιτερότητες, που συγκεκριμενοποιούν τον κατάλληλο αλγόριθμο βελτιστοποίησης. Η Bayesian βελτιστοποίηση έχει αναδειχθεί σε κυρίαρχο αλγοριθμο, καθώς, όπως θα δούμε στην Ενότητα \ref{section:tools}, χρησιμοποιείται σε πολλά \gls{AutoML} εργαλεία.
 \subsubsection{Bayesian Βελτιστοποίηση}
 	\paragraph{Βελτιστοποίηση blackbox συναρτήσεων} Η αναζήτηση των βέλτιστων παραμέτρων γίνεται με άξονα τη μεγιστοποίηση της γενικευμένης απόδοσης: ενός δείκτη που δηλώνει πόσο καλά λειτουργεί το μοντέλο μας σε άγνωστα δεδομένα. Όπως είδαμε στην Ενότητα \ref{section:terminology} σκοπός ενός μοντέλου, και επομένως παράγοντας αξιολόγησής του, είναι η προσέγγιση της πραγματική συνάρτησης, που περιγράφει πώς προκύπτει η υπό μελέτη κλάση από τα χαρακτηριστικά. Η υπόθεση κυρτότητας, που θα εξασφάλιζε την εύρεση ολικού μεγίστου με τοπικό αλγόριθμο αναζήτησης είναι άτοπη, καθώς η επίλυση ενός πραγματικού προβλήματος συνήθως συνεπάγεται πολυπλοκότητα της συνάρτησης που το περιγράφει. Το μόνο που γνωρίζουμε για αυτήν είναι τα δεδομένα που έχουμε, δηλαδή κάποιες εισόδους και εξόδους της, εξού και ο χαρακτηρισμός της ως μαύρο κουτί. Τα διαθέσιμα δεδομένα είναι μάλιστα περιορισμένα, καθώς η απόκτησή τους μπορεί να απαιτεί χρόνο, κόπο και χρήματα (δοκιμές φαρμάκων, οικονομικές επενδύσεις). Η βελτιστοποίηση μιας συνάρτησης f(x) με παραμέτρους από ένα σύνολο A, συμβολίζεται ως:
 \begin{equation}
 \max_{x \in \subset A } f(x)
 \end{equation}
 	Ο όρος Bayesian βελτιστοποίηση εισήχθη από τους \citet{Mockus1991} σε μια σειρά μελετών του για ολική βελτιστοποίηση συναρτήσεων. Βασικά χαρακτηριστικά αυτής της διαδικασίας είναι πως είναι ακολουθιακή, ενσωματώνει κάποια εκ των προτέρων πεποίθηση που έχουμε για την υπό βελτιστοποίηση συνάρτηση, χρησιμοποιεί το θεώρημα Bayes και καθοδηγεί την αναζήτηση του μεγίστου με βάση ένα συνδυασμό μεταξύ εξερεύνησης και εκμετάλλευσης.
 	\paragraph{Θεώρημα Bayes} Σύμφωνα με αυτό το θεώρημα, δεδομένου ενός μοντέλου πρόβλεψης M και ενός συνόλου παρατηρήσεων Ε, η εκ των υστέρων πιθανότητα, δηλαδή η πιθανότητα δεδομένων των παρατηρήσεων Ε να προκύψει το μοντέλο M είναι ανάλογη της πιθανότητας των παρατηρήσεων δεδομένου του μοντέλου επί την εκ των προτέρων πιθανότητα του μοντέλου, με μαθηματικούς όρους:
 	\begin{equation}
 	P(M \mid E) \propto P(E \mid M) \cdot P(M)
 	\end{equation}
 	Η παραπάνω πιθανότητα μας δίνει ένα μέσο για να απαντήσουμε στο πραγματικό ερώτημα: "Δεδομένων των διαθέσιμων παρατηρήσεων ποιο μοντέλο τα περιγράφει καλύτερα και επομένως είναι πιθανότερο να προσεγγίζει την πραγματική συνάρτηση;"
 	\paragraph{Η Γκαουσιανή διαδικασία (Gaussian process) ως εκ των προτέρων πιθανότητα} Η εκ των προτέρων πιθανότητα αντικατοπτρίζει την πεποίθηση που έχουμε για την άγνωστη συνάρτηση, όπως για παράδειγμα την ομαλότητα.
 	
 	Η γκαουσιανή διαδικασία ορίζεται ως μια επέκταση μιας γκαουσιανής κατανομής πολλών μεταβλητών σε μια στοχαστική διαδικασία απείρων διαστάσεων, όπου κάθε πεπερασμένος συνδυασμός διαστάσεων δίνει μια γκαουσιανή κατανομή. Όπως ακριβώς η γκαουσιανή κατανομή δίνει την κατανομή κάποιων μεταβλητών και χαρακτηρίζεται πλήρως από τη μέση τιμή και τη διακύμανσή της, έτσι και η γκαουσιανή διαδικασία αποτελεί μια κατανομή συναρτήσεων που χαρακτηρίζεται από κάποια μέση
 	συνάρτηση και μια συνάρτηση διακύμανσης. Για να κατανοήσουμε καλύτερα τη διαδικασία αυτή, μπορούμε να σκεφτούμε πως όπως μία συνάρτηση επιστρέφει έναν αριθμό $f(x)$ για μία τιμή x, αυτή επιστρέφει τη μέση τιμή και διακύμανση μιας κανονικής κατανομής, που δίνει όλες τις πιθανές τιμές της $f(x)$ για το συγκεκριμένο x.
 	\paragraph{Συνάρτηση απόκτησης} Σε κάθε επανάληψη της Bayesian βελτιστοποίησης επιλέγονται τα επόμενα σημεία αναζήτησης της βέλτιστης τιμή με βάση τα σημεία που έχουν ήδη αξιολογηθεί και την τρέχουσα αντίληψη της πιθανότητας. Για το σκοπό αυτό χρησιμοποιούνται οι συναρτήσεις απόκτησης, οι οποίες μεγιστοποιούνται για σημεία που ενδεχομένως να μεγιστοποιούν και την άγνωστη συνάρτηση. Υπάρχουν διάφορες τεχνικές, ωστόσο η βασική αρχή επιλογής αποτελεί ένα συμβιβασμό μεταξύ "εξερεύνησης" (exploration) και "εκμετάλλευσης" (exploitation): ο εξερευνητικός χαρακτήρας της αναζήτησης εκδηλώνεται με την εισχώρηση σε ανεξερεύνητες περιοχές προκειμένου να αποφευχθεί ο κίνδυνος εμμονής σε κάποιο τοπικό μέγιστο, ενώ ο εκμεταλλευτικός με την προτίμηση περιοχών με εξακριβωμένα καλή απόδοση.
 	\begin{itemize}
 		\item \textbf{Πιθανότητα βελτίωσης (probability of improvement)} Μία από τις πρώτες τεχνικές, που εισήχθη από τους \citet{Kushner}, ήταν αυτή της επιλογής του σημείου $x^+$ με τη μεγαλύτερη πιθανότητα βελτίωσης:
 		\begin{equation}
 		PI(x)= P(f(x) \geq f(x^+)) = \Phi \Big(\frac{\mu(x) - f(x^+)}{\sigma(x)}\Big)
 		\end{equation}
 		
 		όπου $\Phi$ είναι η συνάρτηση κανονικής αθροιστικής κατανομής.
 		
 		Το βασικό της μειονέκτημα τότε ήταν ότι δεν λάμβανε καθόλου υπόψιν της το στοιχείο της εξερεύνησης, το οποίο εισήχθη μέσω της παραμέτρου $\xi$ ως εξής:
 	    \begin{equation}
 	    PI(x)= P(f(x) \geq f(x^+)) = \Phi \Big(\frac{\mu(x) - f(x^+) - \xi}{\sigma(x)} \Big)
 	    \end{equation}
 		
 		Η εισαγωγή της παραμέτρου $\xi$ λύνει μεν το πρόβλημα δίνοντας ένα αντιληπτό κατώφλι στη βελτίωση που επιτυγχάνεται, αποτελεί δε μία σημαντική σχεδιαστική επιλογή. Καθώς για ακατάλληλα μικρή τιμή υπάρχει ο κίνδυνος εγκλωβισμού σε τοπικό μέγιστο, ενώ για μεγάλη τιμή η διαδικασία επιβραδύνεται, η αναζήτηση μπορεί να οδηγηθεί σε σφάλμα.
 		
 		Μία πιο ικανοποιητική προσέγγιση θα ήταν κατά την επιλογή του επόμενου σημείου να μη ληφθεί υπόψιν μόνο η πιθανότητα βελτίωσης, αλλά και το μέγεθος της βελτίωσης. Πιο συγκεκριμένα, θα θέλαμε να ελαχιστοποιήσουμε την προσδοκώμενη απόκλιση από το πραγματικό μέγιστο:
 		\begin{equation}
 		x_{t+1}= argmin \left \{ E(\abs{f_{t+1}(x) -f(x^*)} D_{1:t}) \right \}
 		\end{equation}
 		
 		O Mockus όρισε τη συνάρτηση βελτίωσης ως εξής:
 		\begin{equation}
 		I(x)= \max \Big( f_{t+1} (x) - f(x^*) \Big)
 		\end{equation}
 		δηλαδή η βελτίωση είναι θετική όταν η πρόβλεψη είναι μεγαλύτερη από την μέχρι τώρα καλύτερη τιμή, ειδάλλως μηδέν. Το νέο σημείο βρίσκεται μεγιστοποιώντας την προσδοκώμενη βελτίωση:
 		\begin{equation}
 		x=argmax \left \{ E( \max( f_{t+1}(x) - f(x^*) \mid D_t) \right \}
 		\end{equation}
 		H πιθανότητα διαπίστωσης βελτίωσης I σε μία κανονική κατανομή, που χαρακτηρίζεται από μέση τιμή $\mu(x)$ και διακύμανση $\sigma(x)^2$ υπολογίζεται ως εξής:
 		\begin{equation}\frac{1}{\sqrt[]{2 \pi} \sigma(x)} e^{- \frac{(\mu(x)- f(x^*-I))^2}{s \cdot \sigma(x)^2}}
 		\end{equation} 
 		και η προσδοκώμενη βελτίωση είναι το ολοκλήρωμα της παραπάνω συνάρτησης ως προς I.
 		\item \textbf{Χρήση άνω ορίων εμπιστοσύνης (Upper confidence bounds)} Στην τεχνική αυτή είναι ξεκάθαρη η προσπάθεια συμβιβασμού εξερεύνησης και εκμετάλλευσης. Όπως έχουμε αναφέρει, η μέση τιμή της γκαουσιανής διαδικασίας αποτελεί την τρέχουσα εντύπωση που έχουμε για την άγνωστη συνάρτηση. Μπορούμε να επιλέξουμε πόσο εξερευνητικοί θα είμαστε ορίζοντας πόσες τυπικές αποκλίσεις πέρα από τη μέση τιμή της διαδικασίας θα κινηθούμε.
 	\end{itemize} 	
 	
 	Η προσέγγιση της συνάρτησης $L$ που εμφανίζεται στην Εξίσωση \ref{opt} μπορεί να γίνεται κατεξοχήν με τη χρήση μοντέλου, οπότε ονομάζεται Ακολουθιακή Βελτιστοποίηση βασισμένη σε Μοντέλο (Sequential Model-Based Optimization - \gls{SMBO}). Παραδείγματα χωρίς χρήση μοντέλου είναι οι αλγόριθμοι Random Online Adaptive Racing (ROAR) \citep{Hutter2011}, Covari\-ance Matrix Adaptation Evolution Strategy (CMA-ES) \citep{DBLP:journals/corr/LoshchilovH16} και η Ακολουθιακή Βελτιστοποίηση χωρίς Μοντέλο (Sequential Model-free Optimization - \gls{SMFO})  \citep{7373431}. 
 	
 	
 Ο αλγόριθμος που υλοποιεί τη Bayesian βελτιστοποίηση παραθέτεται στο Παράρτημα \ref{appendix:Alg}
 \subsubsection{Ακολουθιακή βελτιστοποίηση βασισμένη σε μοντέλο} \label{section:SMBO}
 Οι αλγόριθμοι βελτιστοποίησης που χρησιμοποιούν μοντέλα εκπαίδευσης εκκολάφτηκαν από τη διαπίστωση πως η συνάρτηση, $f: \Theta \rightarrow Y$ που καθορίζει πως επιδρούν οι υπερ-παράμετροι στην απόδοση του μοντέλου είναι περίπλοκη και οφείλει να προσεγγιστεί από κάποιο μοντέλο μηχανικής μάθησης. Έτσι, τα δεδομένα εκπαίδευσης έχουν τη μορφή ${(\theta_1,y_1),...,(\theta_n,y_n)}$, όπου $\theta_i=(\theta_{i,1}..., \theta_{i,d})$ οι d παράμετροι και $y_i$ η απόδοση που επετεύχθη με αυτές. Ένας τυπικός αλγόριθμος αυτής της κατηγορίας περιέχει έναν εσωτερικό βρόγχο, όπου επιλέγουμε το σημείο $x^*$, που βελτιστοποιεί την πρόβλεψη, ως το επόμενο σημείο αξιολόγησης της f. Οι αλγόριθμοι διαφοροποιούνται ως προς το κριτήριο που χρησιμοποιούν για να βελτιστοποιήσουν την πρόβλεψη και ποιο μοντέλο εκπαίδευσης χρησιμοποιούν.
 
 Η υπεροχή των \gls{SMBO} έγκειται στη δυνατότητα παρεμβολής (interpolation) μεταξύ παρατηρούμενων σετ υπερ-παραμέτρων και παρέκτασης (extrapolation) σε άγνωστες περιοχές του χώρου υπερ-παραμέτρων. Επίσης, ποσοτικοποιούν τη σημασία κάθε υπερ-παραμέτρου και των μεταξύ τους αλληλεξαρτήσεων. 
 
 Για μία αλγοριθμική περιγραφή των SMBO μπορούμε να ανατρέξουμε στο παράρτημα \ref{appendix:Alg}. Στη συνέχεια θα αναφέρουμε δύο παραδείγματα SMBO αλγορίθμων.
 
 \paragraph{Ακολουθιακή ρύθμιση αλγορίθμου βασισμένη σε μοντέλο (SMAC)} Παρουσιάστηκε το 2011 από τους \citet{Hutter2011} και αποτελεί χαρακτηριστικό παράδειγμα αυτής της οικογένειας. Χρησιμοποιεί  βασισμένα σε παραδείγματα (instance-based - \gls{IBL}) μοντέλα, όπως γκαουσιανά  μοντέλα ακτινικής βάσης, αλλά και δέντρα, όπως τον αλγόριθμο Random Forest. Το κριτήριο επιλογής που χρησιμοποιεί είναι αυτό της προσδοκώμενης βελτίωσης, που αναλύσαμε στο προηγούμενο κεφάλαιο και εδώ ορίζεται ως:
 \begin{equation}
EI_{y^*} (\theta)= \int_{- \infty}^{y^*} (y^* - y) p(y \mid \theta) dy
 \end{equation}
 \paragraph{Δέντρο εκτιμητών Parzen (TPE)}
 Παρουσιάστηκε από τους \citet{Bergstra:2011:AHO:2986459.2986743}. H εμφάνιση του όρου Parzen στην ονομασία αυτή της τεχνικής αποδίδεται στη χρήση του Parzen εκτιμητή, μίας τεχνικής παρεμβολής για προσέγγιση της πυκνότητας πιθανότητας γύρω από ένα σημείο με χρήση γκαουσιανών συναρτήσεων βάσης. Ενώ ο αλγόριθμος SMAC υπολογίζει απευθείας την ποσότητα $p(y \mid \theta)$ κατά την εύρεση της προσδοκώμενης βελτίωσης, εδώ προσεγγίζεται με τη βοήθεια των  $p(\theta \mid y)$ και $ p(y)$. Συγκεκριμένα, μοντελοποιούμε την πιθανότητα $p(\theta \mid y)$ ως μία εκ δύο εκτιμήσεων πυκνότητας, ανάλογα με το αν η απόδοση y έχει ξεπεράσει κάποιο κατώφλι $y^*$:
 $$p(\theta \mid y)=\left\{
 \begin{array}{ll}
 l(\theta)  & \mbox{εάν} \> y < y^* \\
 g(\theta)  & \mbox{εάν} \> y \geq y^*
 \end{array}
 \right.$$
 
 Το σημείο $y^*$ επιλέγεται με τη χρήση μιας παραμέτρου γ, ώστε να αντιστοιχεί στο γ-μόριο των απωλειών του TPE αλγορίθμου μέχρι την παρούσα στιγμή. Η συνάρτηση $l(\theta)$ είναι μια κατανομή που προήλθε από όλες τις προηγούμενες υπερ-παραμέτρους θ που οδήγησαν σε σφάλμα μικρότερο από $y^*$ και η $g(\theta)$ από τις υπόλοιπες. Έτσι, μπορούμε να ερμηνεύσουμε την πρώτη ως μία εκτίμηση της κατανομής των υπερ-παραμέτρων που έχουν καλή απόδοση και τη δεύτερη αυτών που οδηγούν σε χαμηλή.
 
 Οι κατανομές $l(\theta)$ και $g(\theta)$ παρουσιάζουν μία ιεραρχική δομή, καθώς αντιπροσωπεύουν τις υπερ-παραμέτρους και τη συσχέτιση μεταξύ τους. Όσο αφορά τις υπερ-παραμέτρους με συνεχείς τιμές, μπορούμε να φανταστούμε πως έχουμε  υπολογίσει τον Parzen εκτιμητή για κάθε μια από αυτές. Για να υπολογίσουμε την πιθανότητα ενός παραδείγματος υπερ-παραμέτρων $\theta$, ξεκινούμε από την κορυφή του δέντρου και κατευθυνόμαστε προς τα φύλλα ακολουθώντας τις υπερ-παραμέτρους που έχουμε. Η πιθανότητα σε κάθε κόμβο αντιστοιχεί στον Parzen εκτιμητή και τους συνδυάζουμε ακολουθώντας την αντίθετη διαδρομή προς τη ρίζα.
 
 Τελικά, το κριτήριο που μεγιστοποιείται είναι:
 $$EI_{y^{*}}(\theta) \propto (\gamma + \frac{g(\theta)}{l(\theta)} \cdot (1- \gamma))^{-1}  $$
 
 δοκιμάζοντας διάφορους υποψήφιους συνδυασμούς των υπερ-παραμέτρων και επιλέγοντας αυτόν με τη μικρότερη τιμή $g(\theta)/l(\theta)$.
 
 \subsection{Μετα-μάθηση}
 Κατά την προσπάθεια αυτοματοποίησης, αλλά και γενικότερα βελτίωσης της διαδικασίας της μηχανικής μάθησης, συναντάμε τους ακόλουθους περιορισμούς των συμβατικών μοντέλων μάθησης (base learners):
 
 \begin{itemize}
 	\item Τα πρότυπα, τα οποία αναγνωρίζονται στα δεδομένα, ενσωματώνονται στο μοντέλο, με αποτέλεσμα η επανεφαρμογή του να μη δημιουργεί νέα γνώση \citep{Brazdil2009}.
 	\item Δεν υπάρχει προφανής  τρόπος εξαγωγής και επαναχρησιμοποίησης της γνώσης που παράχθηκε σε νέα προβλήματα. 	
 \end{itemize}
 
 Κλειδί για την επίλυση αυτών των προβλημάτων αποτέλεσε η εισαγωγή της έννοιας της μετα-γνώσης. Πρόκειται για γνώση σχετική με την ίδια τη διαδικασία της μάθησης, την οποία προσπαθεί να βελτιώσει ο τομέας της μετα-μάθησης.
 
 Η μετα-μάθηση στοχεύει στην ικανότητα ενός συστήματος να μαθαίνει από παρελθοντικά προβλήματα και να προσαρμόζεται με βάση την εμπειρία του. Δημιουργεί συστήματα ικανά να λάβουν εμπεριστατωμένες αποφάσεις σχετικά με την αυτοματοποίηση προβλημάτων μηχανικής μάθησης και να προσαρμοστούν σε νέα εμπόδια, όπως ένας αναλυτής δεδομένων επιστρατεύει την εμπειρία του κατά την αντιμετώπιση ενός νέου προβλήματος. 
 
 Η μετα-γνώση λαμβάνει τη μορφή μετα-χαρακτηριστικών, τα οποία εξάγονται από το εκάστοτε σετ δεδομένων και προσπαθούν να αποτυπώσουν τη φύση του προβλήματος μάθησης. Σύμφωνα με τη βιβλιογραφία \citep{Brazdil2009} τα μετα-χαρακτηριστικά ανήκουν στις ακόλουθες κατηγορίες:
 \begin{itemize}
 	\item \textbf{απλά, στατιστικά και της θεωρίας πληροφορίας (information-theoretic)} Πρόκειται για μετα-χαρακτηριστικά που περιγράφουν εξολοκλήρου το σετ δεδομένων, όπως το πλήθος των παραδειγμάτων, η συσχέτιση μεταξύ των χαρακτηριστικών, η εντροπία της κλάσης κτλ.
 	\item \textbf{βασισμένα σε μοντέλο (model-based)} Σε αυτά γίνεται εκμετάλλευση των χαρακτηριστικών κάποιας υπόθεσης h, για παράδειγμα εκπαιδεύεται ένα δέντρο απόφασης και συλλέγονται οι υπερ-παράμετροι του.
 	\item \textbf{ορόσημα (landmarks)} H απόδοση ετερογενών αλγορίθμων μάθησης αποτελεί πληροφορία για τη φύση ενός σετ δεδομένων. 
 \end{itemize}
 
 Πεδίο εφαρμογής της μετα-μάθησης μπορεί να αποτελέσει οποιοδήποτε στάδιο της διαδικασίας μηχανικής μάθησης, όπως η προεπεξεργασία, η επιλογή αλγορίθμου και η ρύθμιση ενός μοντέλου. Σχετικές προσπάθειες στον τομέα της αυτοματοποιημένης μηχανικής μάθησης αποτελούν οι \citet{AAAI1510029}, οι οποίοι χρησιμοποιούν μετα-μάθηση για να αρχικοποιήσουν την αναζήτηση υπερ-παραμέτρων και οι \citet{Soares2004}, οι οποίοι εισάγουν μία μέθοδο επιλογής του πλάτους ενός γκαουσιανού πυρήνα για ένα μοντέλο \gls{SVM} παλινδρόμησης.   
 
 \subsection{Σύγχρονα εργαλεία} \label{section:tools}
 Αν αναλογιστεί κανείς το εύρος των εφαρμογών μηχανικής μάθησης, θα κατανοήσει την ύπαρξη πληθώρας εργαλείων που επιχειρούν να την αυτοματοποιήσουν. Βιβλιοθήκες σε διάφορες γλώσσες παρέχουν διεπαφές προς τεχνικές αυτοματοποίησης, διαδικτυακά περιβάλλοντα αναλαμβάνουν τη διαιτησία ολόκληρης της διαδικασίας της μηχανικής μάθησης προσφέροντας δυνατότητες αυτόματης βελτιστοποίησης της~\footnote{https://azure.microsoft.com/en-us/} και λογισμικά εξειδικευμένα στην ανάλυση δεδομένων ενσωματώνουν διεπαφές προς υλοποιημένους αλγορίθμους βελτιστοποίησης. Η εμπορική σημασία της αυτόματης επίτευξης μοντέλων πρόβλεψης έχει οδηγήσει στην κυκλοφορία πολλών εμπορικών εργαλείων, αλλά και οι κοινότητες ελεύθερου λογισμικού έχουν κινητοποιηθεί μπροστά σε αυτήν την πολύπλευρη ανάγκη. Στη συνέχεια θα δούμε μερικά χαρακτηριστικά εργαλεία.
 \paragraph[HPOlib]{HPOlib~\footnote{https://github.com/automl/HPOlib} }  Πρόκειται για μία βιβλιοθήκη βελτιστοποίησης υπερπαραμέτρων, που παρέχει μία κοινή διεπαφή προς τρία σύγχρονα, αναγνωρισμένα πακέτα: 
 \begin{itemize}
 	\item \textit{ SMAC.} Ο αλγόριθμος αυτός, γραμμένος σε python, έχει περιγραφεί στην Ενότητα \ref{section:SMBO}.
 	\item \textit{ Spearmint.} Γραμμένο σε python, χρησιμοποιείται για την εφαρμογή bayesian βελτιστοποίησης.
 	\item \textit{ Hyperopt.} Γραμμένο σε python, αναλαμβάνει τη βελτιστοποίηση σε απαιτητικούς χώρους αναζήτησης με τη χρήση τυχαία αναζήτησης και του αλγορίθμου TPE.
 \end{itemize}
 
 \paragraph[auto-sklearn]{auto-sklearn~\footnote{https://github.com/automl/auto-sklearn} } Μία εργαλειοθήκη αυτοματοποιημένης μηχανικής μάθησης,η οποία με βάση την python βιβλιοθήκη scikit-learn~\footnote{http://scikit-learn.org/stable/} και χρήση Bayesian βελτιστοποίησης, μετα-μάθησης και ensembles αναλαμβάνει την παραγωγή μοντέλων μηχανικής μάθησης.
 
    
 \paragraph[Auto-WEKA]{Auto-WEKA~\footnote{http://www.cs.ubc.ca/labs/beta/Projects/autoweka/} }  Το Waikato Environment for Knowledge Analysis (Weka) είναι ένα λογισμικό σχετικό με τους τομείς της ανάλυσης δεδομένων και μοντέλων πρόβλεψης. Υλοποιεί πληθώρα αλγορίθμων μηχανικής μάθησης, γραμμένων σε Java, και παρέχει γραφικές διεπαφές και εργαλεία οπτικοποίησης για διευκόλυνση των χρηστών. Το λογισμικό αυτό έχει ενσωματώσει την αυτοματοποίηση της μηχανικής μάθησης στο Auto-WEKA, που εισήχθη το 2013 \citep{DBLP:journals/corr/abs-1208-3719} και αναλαμβάνει την επίλυση του προβλήματος  CASH (εξίσωση \ref{optCash}) . Συνεχίζοντας την παράδοση του εργαλείου αυτού στην απλότητα χρήσης, το Auto-WEKA αντιμετωπίζεται ως ένας απλός αλγόριθμος μάθησης, που αναλαμβάνει την επιλογή των χαρακτηριστικών, του μοντέλου και  τη βελτιστοποίηση των υπερ-παραμέτρων, ανάμεσα σε όλες τις τεχνικές και αλγορίθμους που προσφέρει το WEKA. Για να επιλύσει αυτό το πολυδιάστατο πρόβλημα έχει βασιστεί σε SMBO αλγορίθμους (SMAC, TPE).  
 \paragraph[caret]{R \& caret~\footnote{http://caret.r-forge.r-project.org/} }  Το πακέτο caret είναι γραμμένο σε R, μία γλώσσα προγραμματισμού και ένα περιβάλλον λογισμικού εξειδικευμένο στη στατιστική. Η R είναι το κατεξοχήν εργαλείο για συγγραφή κώδικα σε εφαρμογές στατιστικής, ανάλυσης δεδομένων και μηχανικής μάθησης και  διαθέτει πακέτα που επιτελούν πληθώρα αλγορίθμων και τεχνικών, καθώς και εργαλείων οπτικοποίησης. Οι κοινότητες ελεύθερου λογισμικού έχουν εξοπλίσει την R με πακέτα που επιχειρούν τη βελτιστοποίηση της μηχανικής μάθησης, όπως αυτόματης προεπεξεργασίας δεδομένων και  ρύθμισης μοντέλου, οι διεπαφές των οποίων είναι αναμενόμενα ανομοιόμορφες.  Το πακέτο classification and regression training, caret, αποτελεί προσπάθεια τυποποίησης της διαδικασίας της εκπαίδευσης παρέχοντας ομοιόμορφες διεπαφές και  εργαλεία για διαχωρισμό των δεδομένων, προ επεξεργασία, επιλογή χαρακτηριστικών, ρύθμιση των υπερ-παραμέτρων του μοντέλου, εκτίμηση της σημασίας των χαρακτηριστικών και άλλων λειτουργιών χρήσιμων στην προσπάθεια αυτοματοποίησης της εκπαίδευσης ενός μοντέλου.
 \paragraph{Google AutoML} Η ερευνητική ομάδα AutoML της Google παρουσιάστηκε στο συνέδριο Google I/O '17~\footnote{https://www.youtube.com/watch?v=Y2VF8tmLFHw}. Επικεντρώνεται σε μοντέλα βαθιάς μάθησης (deep learning) και βασίζεται στην ακόλουθη λογική: ένα νευρωνικό δίκτυο-ελεγκτής προτείνει μία αρχιτεκτονική, η οποία εκπαιδεύεται και αξιολογείται η απόδοσή της σε κάποιο συγκεκριμένο πρόβλημα. Στη συνέχεια το δίκτυο-ελεγκτής αποφασίζει πως θα βελτιώσει την υπάρχουσα αρχιτεκτονική με βάση την πληροφορία της αξιολόγησης. Το εργαλείο αυτό έχει εφαρμοστεί σε προβλήματα αναγνώρισης εικόνας και ομιλίας και στοχεύει στη διευκόλυνση της εφαρμογής deep learning, ώστε να είναι προσβάσιμη σε μη-ειδικούς.
 